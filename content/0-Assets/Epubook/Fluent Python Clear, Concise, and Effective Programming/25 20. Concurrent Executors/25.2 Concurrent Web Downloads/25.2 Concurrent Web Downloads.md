# Concurrent Web Downloads

Concurrency is essential for efficient network I/O: instead of idly waiting for remote machines, the application should do something else until a response comes back.[^2]

To demonstrate with code, I wrote three simple programs to download 0-Assets/Epubook/Fluent%20Python%20Clear,%20Concise,%20and%20Effective%20Programming/images of 20 country flags from the web. The first one, _flags.py_, runs sequentially: it only requests the next image when the previous one is downloaded and saved locally. The other two scripts make concurrent downloads: they request several 0-Assets/Epubook/Fluent%20Python%20Clear,%20Concise,%20and%20Effective%20Programming/images practically at the same time, and save them as they arrive. The _flags_threadpool.py_ script uses the `concurrent.futures` package, while _flags_asyncio.py_ uses `asyncio`.

[Example 20-1](#ex_flags_sample_runs) shows the result of running the three scripts, three times each. I also posted a [73s video on YouTube](https://fpy.li/20-3) so you can watch them running while a macOS Finder window displays the flags as they are saved. The scripts are downloading 0-Assets/Epubook/Fluent%20Python%20Clear,%20Concise,%20and%20Effective%20Programming/images from _fluentpython.com_, which is behind a CDN, so you may see slower results in the first runs. The results in [Example 20-1](#ex_flags_sample_runs) were obtained after several runs, so the CDN cache was warm.

##### Example 20-1. Three typical runs of the scripts flags.py, flags_threadpool.py, and flags_asyncio.py

```
$ python3 flags.py
BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN  
```

[![^1]

The output for each run starts with the country codes of the flags as they are downloaded, and ends with a message stating the elapsed time.

[![^2]

It took _flags.py_ an average 7.18s to download 20 0-Assets/Epubook/Fluent%20Python%20Clear,%20Concise,%20and%20Effective%20Programming/images.

[![^3]

The average for _flags_threadpool.py_ was 1.40s.

[![^4]

For _flags_asyncio.py_, 1.35s was the average time.

[![^5]

Note the order of the country codes: the downloads happened in a different order every time with the concurrent scripts.

The difference in performance between the concurrent scripts is not significant, but they are both more than five times faster than the sequential script—and this is just for the small task of downloading 20 files of a few kilobytes each. If you scale the task to hundreds of downloads, the concurrent scripts can outpace the sequential code by a factor or 20 or more.

###### Warning

While testing concurrent HTTP clients against public web servers, you may inadvertently launch a denial-of-service (DoS) attack, or be suspected of doing so. In the case of [Example 20-1](#ex_flags_sample_runs), it’s OK to do it because those scripts are hardcoded to make only 20 requests. We’ll use Python’s `http.server` package to run tests later in this chapter.

Now let’s study the implementations of two of the scripts tested in [Example 20-1](#ex_flags_sample_runs): _flags.py_ and _flags_threadpool.py_. I will leave the third script, _flags_asyncio.py_, for [Chapter 21](ch21.html#async_ch), but I wanted to demonstrate all three together to make two points:

1. Regardless of the concurrency constructs you use—threads or coroutines—you’ll see vastly improved throughput over sequential code in network I/O operations, if you code it properly.
    
2. For HTTP clients that can control how many requests they make, there is no significant difference in performance between threads and coroutines.[^3]
    

On to the code.