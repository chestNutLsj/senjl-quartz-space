# Vector Take #4: Hashing and a Faster ==

Once more we get to implement a `__hash__` method. Together with the existing `__eq__`, this will make `Vector` instances hashable.

The `__hash__` in `Vector2d` ([Example 11-8](ch11.html#ex_vector2d_v3_hash)) computed the hash of a `tuple` built with the two components, `self.x` and `self.y`. Now we may be dealing with thousands of components, so building a `tuple` may be too costly. Instead, I will apply the `^` (xor) operator to the hashes of every component in succession, like this: `v[0] ^ v[1] ^ v[2]`. That is what the `functools.reduce` function is for. Previously I said that `reduce` is not as popular as before,[^4] depicts the general idea of the `reduce` function.

![Reduce diagram](assets/flpy_1201.png)

###### Figure 12-1. Reducing functions—`reduce`, `sum`, `any`, `all`—produce a single aggregate result from a sequence or from any finite iterable object.

So far we’ve seen that `functools.reduce()` can be replaced by `sum()`, but now let’s properly explain how it works. The key idea is to reduce a series of values to a single value. The first argument to `reduce()` is a two-argument function, and the second argument is an iterable. Let’s say we have a two-argument function `fn` and a list `lst`. When you call `reduce(fn, lst)`, `fn` will be applied to the first pair of elements—`fn(lst[0], lst[1])`—producing a first result, `r1`. Then `fn` is applied to `r1` and the next element—`fn(r1, lst[2])`—producing a second result, `r2`. Now `fn(r2, lst[3])` is called to produce `r3` … and so on until the last element, when a single result, `rN`, is returned.

Here is how you could use `reduce` to compute `5!` (the factorial of 5):

```
>>> 
```

Back to our hashing problem, [Example 12-11](#ex_reduce_xor) shows the idea of computing the aggregate xor by doing it in three ways: with a `for` loop and two `reduce` calls.

##### Example 12-11. Three ways of calculating the accumulated xor of integers from 0 to 5

```
>>> 
```

[![^1]

Aggregate xor with a `for` loop and an accumulator variable.

[![^2]

`functools.reduce` using an anonymous function.

[![^3]

`functools.reduce` replacing custom `lambda` with `operator.xor`.

From the alternatives in [Example 12-11](#ex_reduce_xor), the last one is my favorite, and the `for` loop comes second. What is your preference?

As seen in [“The operator Module”](ch07.html#operator_module_section), `operator` provides the functionality of all Python infix operators in function form, lessening the need for `lambda`.

To code `Vector.__hash__` in my preferred style, we need to import the `functools` and `operator` modules. [Example 12-12](#ex_vector_v4) shows the relevant changes.

##### Example 12-12. Part of vector_v4.py: two imports and `__hash__` method added to the `Vector` class from vector_v3.py

```
from
```

[![^1]

Import `functools` to use `reduce`.

[![^2]

Import `operator` to use `xor`.

[![^3]

No change to `__eq__`; I listed it here because it’s good practice to keep `__eq__` and `__hash__` close in source code, because they need to work together.

[![^4]

Create a generator expression to lazily compute the hash of each component.

[![^5]

Feed `hashes` to `reduce` with the `xor` function to compute the aggregate hash code; the third argument, `0`, is the initializer (see the next warning).

###### Warning

When using `reduce`, it’s good practice to provide the third argument, `reduce(function, iterable, initializer)`, to prevent this exception: `TypeError: reduce() of empty sequence with no initial value` (excellent message: explains the problem and how to fix it). The `initializer` is the value returned if the sequence is empty and is used as the first argument in the reducing loop, so it should be the identity value of the operation. As examples, for `+`, `|`, `^` the `initializer` should be `0`, but for `*`, `&` it should be `1`.

As implemented, the `__hash__` method in [Example 12-12](#ex_vector_v4) is a perfect example of a map-reduce computation ([Figure 12-2](#map_reduce_fig)).

![Map-reduce diagram](assets/flpy_1202.png)

###### Figure 12-2. Map-reduce: apply function to each item to generate a new series (map), then compute the aggregate (reduce).

The mapping step produces one hash for each component, and the reduce step aggregates all hashes with the `xor` operator. Using `map` instead of a _genexp_ makes the mapping step even more visible:

    `def` `__hash__``(``self``):`
        `hashes` `=` `map``(``hash``,` `self``.``_components``)`
        `return` `functools``.``reduce``(``operator``.``xor``,` `hashes``)`

###### Tip

The solution with `map` would be less efficient in Python 2, where the `map` function builds a new `list` with the results. But in Python 3, `map` is lazy: it creates a generator that yields the results on demand, thus saving memory—just like the generator expression we used in the `__hash__` method of [Example 12-8](#ex_vector_v3_getattr).

While we are on the topic of reducing functions, we can replace our quick implementation of `__eq__` with another one that will be cheaper in terms of processing and memory, at least for large vectors. As introduced in [Example 11-2](ch11.html#ex_vector2d_v0), we have this very concise implementation of `__eq__`:

    `def` `__eq__``(``self``,` `other``):`
        `return` `tuple``(``self``)` `==` `tuple``(``other``)`

This works for `Vector2d` and for `Vector`—it even considers `Vector([1, 2])` equal to `(1, 2)`, which may be a problem, but we’ll overlook that for now.[^5].

##### Example 12-13. The `Vector.__eq__` implementation using `zip` in a `for` loop for more efficient comparison

```
    
```

[![^1]

If the `len` of the objects are different, they are not equal.

[![^2]

`zip` produces a generator of tuples made from the items in each iterable argument. See [“The Awesome zip”](#zip_box) if `zip` is new to you. In ![^1], the `len` comparison is needed because `zip` stops producing values without warning as soon as one of the inputs is exhausted.

[![^3]

As soon as two components are different, exit returning `False`.

[![^4]

Otherwise, the objects are equal.

###### Tip

The `zip` function is named after the zipper fastener because the physical device works by interlocking pairs of teeth taken from both zipper sides, a good visual analogy for what `zip(left, right)` does. No relation to compressed files.

[Example 12-13](#ex_eq_loop) is efficient, but the `all` function can produce the same aggregate computation of the `for` loop in one line: if all comparisons between corresponding components in the operands are `True`, the result is `True`. As soon as one comparison is `False`, `all` returns `False`. [Example 12-14](#ex_eq_all) shows how `__eq__` looks using `all`.

##### Example 12-14. The `Vector.__eq__` implementation using `zip` and `all`: same logic as [Example 12-13](#ex_eq_loop)

    `def` `__eq__``(``self``,` `other``):`
        `return` `len``(``self``)` `==` `len``(``other``)` `and` `all``(``a` `==` `b` `for` `a``,` `b` `in` `zip``(``self``,` `other``))`

Note that we first check that the operands have equal length, because `zip` will stop at the shortest operand.

[Example 12-14](#ex_eq_all) is the implementation we choose for `__eq__` in _vector_v4.py_.

##### The Awesome zip

Having a `for` loop that iterates over items without fiddling with index variables is great and prevents lots of bugs, but demands some special utility functions. One of them is the `zip` built-in, which makes it easy to iterate in parallel over two or more iterables by returning tuples that you can unpack into variables, one for each item in the parallel inputs. See [Example 12-15](#zip_demo).

##### Example 12-15. The `zip` built-in at work

```
>>> 
```

[![^1]

`zip` returns a generator that produces tuples on demand.

[![^2]

Build a `list` just for display; usually we iterate over the generator.

[![^3]

`zip` stops without warning when one of the iterables is exhausted.

[![^4]

The `itertools.zip_longest` function behaves differently: it uses an optional `fillvalue` (`None` by default) to complete missing values so it can generate tuples until the last iterable is exhausted.

# New zip() Option in Python 3.10

I wrote in the first edition of this book that `zip` silently stopping at the shortest iterable was surprising—not a good trait for an API. Silently ignoring part of the input can cause subtle bugs. Instead, `zip` should raise `ValueError` if the iterables are not all of the same length, which is what happens when unpacking an iterable to a tuple of variables of different length—in line with Python’s _fail fast_ policy. [PEP 618—Add Optional Length-Checking To zip](https://fpy.li/pep618) added an optional `strict` argument to `zip` to make it behave in that way. It is implemented in Python 3.10.

The `zip` function can also be used to transpose a matrix represented as nested iterables. For example:

```
>>> 
```

If you want to grok `zip`, spend some time figuring out how these examples work.

The `enumerate` built-in is another generator function often used in `for` loops to avoid direct handling of index variables. If you’re not familiar with `enumerate`, you should definitely check it out in the [“Built-in functions” documentation](https://fpy.li/12-3). The `zip` and `enumerate` built-ins, along with several other generator functions in the standard library, are covered in [“Generator Functions in the Standard Library”](ch17.html#stdlib_generators).

We wrap up this chapter by bringing back the `__format__` method from `Vector2d` to `Vector`.