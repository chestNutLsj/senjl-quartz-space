### 7.5.1　数据的归一化

在被输入神经网络之前，待处理的数据集通常需要进行一些清理。清理可能会包括移除无关字符、删除重复项、修复错误和其他琐事。对于即将被处理的两个数据集，需要执行的清理工作就是归一化。在第6章中，我们用`KMeans`类中的`zscore_normalize()`方法完成了归一化。归一化就是读取以不同尺度（scale）记录的属性值，并将它们转换为相同的尺度。

因为有了sigmoid激活函数，神经网络中的每个神经元都会输出0到1之间的值。看来0到1之间的尺度对于输入数据集中的属性也有意义是合乎逻辑的。将尺度从某一范围转换为0到1之间的范围并没有什么挑战性。对于最大值为`max`、最小值为`min`的某个属性范围内的任意值V，转换公式就是`newV =（oldV - min）/（max - min）`。此操作被称为特征缩放（feature scaling）。代码清单7-13给出的是加入util.py中的一种Python实现。

代码清单7-13　util.py（续）

```
# assume all rows are of equal length
# and feature scale each column to be in the range 0 - 1
def normalize_by_feature_scaling(dataset: List[List[float]]) -> None:
    for col_num in range(len(dataset[0])):
        column: List[float] = [row[col_num] for row in dataset]
        maximum = max(column)
        minimum = min(column)
        for row_num in range(len(dataset)):
            dataset[row_num][col_num] = (dataset[row_num][col_num] - minimum) / 
             (maximum - minimum)
```

看一下参数`dataset`。它是一个引用，指向即将在原地被修改的列表的列表。换句话说，`normalize_by_feature_scaling()`收到的不是数据集的副本，而是对原始数据集的引用。这里是要对值进行修改，而不是接收转换过的副本。

另外请注意，本程序假定数据集是由`float`类型数据构成的二维列表。