### 7.2.3　反向传播

最后一部分，也是最复杂的部分，就是反向传播。反向传播将在神经网络的输出中发现误差，并用它来修正神经元的权重。某个神经元对误差担负的责任越大，对其修正就会越多。但误差从何而来？我们如何才能知道存在误差呢？

误差由被称为训练（training）的神经网络应用阶段获得。

---

  

**提示**　本节会有几个步骤写成了数学公式。伪公式（符号不一定很恰当）写在了配图中。这种写法将让那些对数学符号不在行（或生疏）的人更容易读懂这些公式。如果你对更正规的符号（及公式的推导）感兴趣，请查看Russell和Norvig的《人工智能：一种现代的方法（第3版）》的第18章[^1]。

---

  

大多数神经网络在使用之前，都必须经过训练。我们必须知道通过某些输入能够获得的正确输出，以便用预期输出和实际输出的差异来查找误差并修正权重。换句话说，神经网络在最开始时是一无所知的，直至它们知晓对于某组特定输入集的正确答案，在这之后才能为其他输入做好准备。反向传播仅发生在训练期间。

---

  

**注意**　因为大多数神经网络都必须经过训练，所以其被认为是一种监督机器学习。请回想一下第6章，_k_均值聚类算法和其他聚类算法被认为是一种无监督机器学习算法，因为它们一旦启动就无须进行外部干预。除本章介绍的这种神经网络之外，其他还有一些类型的神经网络是不需要预训练的，那些神经网络可被视为无监督机器学习。

---

  

反向传播的第一步，是计算神经网络针对某些输入的输出与预期输出之间的误差。输出层中的所有神经元都会具有这一误差（每个神经元都有一个预期输出及其实际输出）。然后，输出神经元的激活函数的导数将会应用于该神经元在其激活函数被应用之前输出的值（这里缓存了一份应用激活函数前的输出值）。将求导结果再乘以神经元的误差，求其delta。求delta公式用到了偏导数，其微积分推导过程超出了本书的范围，大致就是要计算出每个输出神经元承担的误差量。有关此计算的示意图，如图7-4所示。

![..\20-0103 改图\figure7_4.tif](../0-Assets/Epubook/算法精粹：经典计算机科学问题的%20Python%20实现%20(David%20Kopec%20[Kopec,%20David])%20(Z-Library)/images/00042.jpeg)

图7-4　在训练的反向传播阶段计算输出神经元的delta的机制

然后必须为网络所有隐藏层中的每个神经元计算delta。每个神经元对输出层的不正确输出所承担的责任都必须明确。输出层中的delta将会用于计算上一个隐藏层中的delta。根据下层各神经元权重的点积和在下层中已算出的delta，可以算出上一层的delta。将这个值乘以调用神经元最终输出（在调用激活函数之前已缓存）的激活函数的导数，即可获得当前神经元的delta。同样，这个公式是用偏导数推导得出的，有关介绍可以在更专业的数学课本中找到。

图7-5呈现了隐藏层中各神经元的delta的实际计算过程。在包含多个隐藏层的网络中，神经元O1、O2和O3可能不属于输出层，而属于下一个隐藏层。

![..\20-0103 a\figure7_5.tif](../0-Assets/Epubook/算法精粹：经典计算机科学问题的%20Python%20实现%20(David%20Kopec%20[Kopec,%20David])%20(Z-Library)/images/00043.jpeg)

图7-5　隐藏层中神经元的delta的计算过程

最重要的一点是，网络中每个神经元的权重都必须进行更新，更新方式是把每个权重的最近一次输入、神经元的delta和一个名为学习率（learning rate）的数相乘，再将结果与现有权重相加。这种改变神经元权重的方式被称为梯度下降（gradient descent）。这就像爬一座小山，表示神经元的误差函数向最小误差的点不断靠近。delta代表了爬山的方向，学习率则会影响攀爬的速度。不经过反复的试错，很难为未知的问题确定良好的学习率。图7-6呈现了隐藏层和输出层中每个权重的更新方式。

![..\20-0103 a\figure7_6.tif](../0-Assets/Epubook/算法精粹：经典计算机科学问题的%20Python%20实现%20(David%20Kopec%20[Kopec,%20David])%20(Z-Library)/images/00044.jpeg)

图7-6　用前面步骤求得的delta、原权重、原输入和用户指定的学习率  
更新每个隐藏层和输出层中神经元的权重

一旦权重更新完毕，神经网络就可以用其他输入和预期输出再次进行训练。此过程将一直重复下去，直至该神经网络的用户认为其已经训练好了，这可以用正确输出已知的输入进行测试来确定。

反向传播确实比较复杂。如果你还未掌握所有细节，请不必担心。仅凭本节的讲解可能还不够充分。在理想情况下，编写反向传播算法的实现代码会提升你对它的理解程度。在实现神经网络和反向传播时，请牢记一个首要主题：反向传播是一种根据每个权重对造成不正确输出所承担的责任来调整该权重的方法。