   

## 7.7　神经网络问题及其扩展

得益于在深度学习方面所取得的进步，神经网络现在正在风靡，但它有一些显著的缺点。最大的问题是神经网络解决方案是一种类似于黑盒的模型。即便运行一切正常，用户也无法深入了解神经网络是如何解决问题的。例如，在本章中我们构建的鸢尾花数据集分类程序并没有明确展示输入的4个参数分别对输出的影响程度。在对每个样本进行分类时，萼片长度比萼片宽度更为重要吗？

如果对已训练网络的最终权重进行仔细分析，是有可能得出一些见解的，但这种分析并不容易，并且无法做到像线性回归算法那么精深，线性回归可以对被建模的函数中每个变量的作用做出解释。换句话说，神经网络可以解决问题，但不能解释问题是如何解决的。

神经网络的另一个问题是，为了达到一定的准确度，通常需要数据量庞大的数据集。想象一下户外风景图的分类程序。它可能需要对数千种不同类型的图像（森林、山谷、山脉、溪流、草原等）进行分类。训练用图可能就需要数百万张。如此大型的数据集不但难以获取，而且对某些应用程序而言可能根本就不存在。为了收集和存储如此庞大的数据集而拥有数据仓库和技术设施的，往往都是大公司和政府机构。

最后，神经网络的计算代价很高。可能大家已经注意到了，只是鸢尾花数据集的训练过程就能让Python解释器不堪重负。纯Python环境下（不带NumPy之类的C支持库）的计算性能是不太理想，但最要紧的是，在任何采用神经网络的计算平台上，训练过程都必须执行大量的计算，这会耗费很多时间。提升神经网络性能的技巧有很多（如使用SIMD指令或GPU），但训练神经网络终究还是需要执行大量的浮点运算。

有一条告诫非常好，就是训练神经网络比实际运用神经网络的计算成本高。某些应用程序不需要持续不断的训练。在这些情况下，只要把训练完毕的神经网络放入应用程序，就能开始求解问题了。例如，Apple的Core ML框架的第一个版本甚至不支持训练。它只能帮助应用程序开发人员在自己的应用程序中运行已训练过的神经网络模型。照片应用程序的开发人员可以下载免费的图像分类模型，将其放入Core ML，马上就能开始在应用程序中使用高性能的机器学习算法了。

本章只构建了一类神经网络，即带反向传播的前馈网络。如上所述，还有很多其他类型的神经网络。卷积神经网络也是前馈的，但它具有多个不同类型的隐藏层、各种权重分配机制和其他一些有意思的属性，使其特别适用于图像分类。而在反馈神经网络中，信号不只是往一个方向传播。它们允许存在反馈回路，并已经证明能有效应用于手写识别和语音识别等连续输入类应用。

我们可以对本章的神经网络进行一种简单的扩展，即引入偏置神经元（bias neuron），这会提升网络的性能。偏置神经元就像某个层中的一个虚拟神经元（dummy neuron），它允许下一层的输出能够表达更多的函数，这可以通过给定一个常量输入（仍通过权重进行修改）来实现。在求解现实世界的问题时，即便是简单的神经网络通常也会包含偏置神经元。如果在本章的现有神经网络中添加了偏置神经元，我们可能只需较少的训练就能达到相近级别的准确度。