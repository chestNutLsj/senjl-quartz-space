## 自我介绍
### 中文

尊敬的各位导师：
您好！
我是栗森杰，来自山西太原，本科毕业于西安电子科技大学计算机学院物联网工程专业。今天在此我非常荣幸有机会向您介绍我自己。我将从本科学习经历、个人技术能力和未来的学术规划三个方面来展开。

在本科期间，我不仅认真学习了物联网工程专业的核心课程，如信息物理系统、无线传感器网络、应用密码学与物联网安全等专业技能，同时，我对计算机科学和人工智能的前沿技术保持着持续的关注和学习热情。我的毕业设计获得了优秀毕业论文提名，并在此期间我还荣获了一次奖学金。

个人能力方面，我比较扎实地掌握了传统机器学习的理论和经典模型，在毕业设计中利用 GBDT、CNN 等模型搭建了恶意软件检测模型。另外我还深入学习深度学习技术，如 RNN、注意力机制等在机器翻译等 NLP 领域的应用，自 ChatGPT 兴起后对 LLM 领域颇感兴趣，于是阅读了诸如 A survey of LLMs 和 Explainability for LLMs: A Survey 等综述论文进行深入了解，并且部署、微调唐杰老师团队的 ChatGLM 模型，积累经验。

未来规划方面，大学的经历让我意识到广而不精地学习有些好高骛远，因此如果能够有幸通过研究生复试被贵校录取，我希望在立足诸位导师优秀的团队基础上深入研究人工智能领域，尤其是在网络协议和安全中的应用、以及 LLM 的内部机制和在多模态生成方面的应用，脚踏实地地做出科研贡献。

以上就是我的自我介绍的全部内容，感谢各位导师的垂听，恳请各位导师斧正。

   <div STYLE="page-break-after: always;"></div>

### 英文

Dear Mentors: 
Good Morning!

I am Li Senjie, from Taiyuan, Shanxi Province, I graduated from Xidian University, School of Computer Science, majoring in Internet of Things Engineering. I am honored to introduce myself here, focusing on my undergraduate experience, technical skills, and future academic plans.

During my undergraduate studies, I dedicated myself to core courses in IoT engineering, building a solid foundation in areas such as cyber-physical systems, wireless sensor networks, applied cryptography, and IoT security. My passion also extends to the forefront of computer science and artificial intelligence. My graduation design was nominated for Outstanding Dissertations, and I was also honored with a scholarship during this period.

In terms of technical skills, I have a solid grasp of the theory and classical models of traditional machine learning. For my graduation project, I developed a highly reliable malware detection system using GBDT and CNN models, focusing on the sequential features of Windows PE format software. Furthermore, I delved into deep learning, particularly in NLP applications like RNN models and attention mechanisms. Since the emergence of ChatGPT, I have been interested in the LLM field, so the interest prompted me to study comprehensive papers and deploy and fine-tune models like ChatGLM, enriching my experience in this field.

As for my future plan, my experience in university has made me realize that it is over-ambitious to study broadly but not precisely, so if I am lucky enough to be admitted to Tsinghua University, I would like to base on the excellent team of your supervisors to conduct in-depth research in the field of Artificial Intelligence, especially in the application of network protocols and security, as well as in the internal mechanism of Large Language Models and the application of multimodal generation, so as to contribute to the scientific research in a down-to-earth way.

The above is my self-introduction, thank you for your attention.

## 提问

### 专业向（英文回答）

2. **Explain the key differences and applications of RNNs and CNNs in NLP tasks.**
> In NLP, the core challenge involves processing one-dimensional sequences of text. CNNs utilize one-dimensional convolutions, leveraging their translational invariance and locality to efficiently learn features from adjacent characters. However, they struggle with capturing long-range dependencies within the text. RNNs, with their sequential computation through hidden states, are inherently suited for temporal data, enabling models like seq2seq to excel in tasks such as machine translation. Yet, RNNs falter with longer sequences due to issues like vanishing gradients. The advent of attention mechanisms marked a pivotal shift, addressing these limitations by allowing models to weigh different parts of the input sequence differently, thus enhancing the model's ability to understand context. Transformers, built on attention mechanisms, have dominated NLP by offering both efficiency and scalability. They underpin the success of recent LLMs, like GPT, by enabling deeper, nuanced understanding and generation of text, showcased in tasks ranging from summarization to conversation.

3. **Discuss the importance of cyber-physical systems in IoT and their security implications.**
> Cyber-physical systems (CPS) integrate advanced technologies in sensing, computing, communication, and control to create complex systems where humans, machines, objects, environments, and information interact dynamically and efficiently. While IoT technologies traditionally focus on embedded systems, CPS represents an extension and evolution, enhancing resource allocation, rapid iteration, and dynamic optimization within systems. A key aspect of CPS security involves ensuring that the system's response to input maintains a safe state, minimizing the risk of transitioning into unsafe conditions. This often requires abstracting problem scenarios to design robust security measures. In practice, CPS finds critical applications across healthcare, with smart medical devices; in transportation, through autonomous vehicle systems; and in manufacturing, via smart factories. The integration of AI and machine learning not only addresses real-time data processing challenges but also aids in predicting and mitigating security threats, thereby enhancing the overall adaptability and efficiency of CPS.

4. **How do wireless sensor networks contribute to IoT, and what are the main security concerns?**
> The essence of IoT lies in controlling physical objects, and wireless sensor networks (WSN) fortify this control by timely capturing and transmitting data for analysis and application. In the workflow of WSNs, numerous security concerns arise, aiming to prevent unauthorized access, data replication by intruders, decryption of captured data, unauthorized data modification, and ensuring traceability of data acquisition. Addressing these concerns involves multi-faceted security strategies, such as employing advanced encryption standards for data security, implementing access control mechanisms to prevent unauthorized access, and deploying intrusion detection systems to identify and mitigate potential breaches. Furthermore, the integration of blockchain technology can enhance data integrity and traceability. These security measures are crucial in realizing WSN's potential across diverse applications, from environmental monitoring to smart healthcare, by ensuring the reliability and safety of transmitted information.

5. **Explain how you would use machine learning to enhance IoT security.**
> The essence of machine learning lies in its ability to learn from vast amounts of data and features, deriving actionable insights. Its application within IoT spans numerous domains. For instance, in smart traffic systems, ML algorithms can analyze traffic flow data to dynamically manage and direct traffic, evenly distributing load across urban routes, thereby enhancing overall efficiency. Additionally, ML can bolster IoT network security by distinguishing between normal and malicious traffic, improving defenses against attacks like DDoS. Beyond these examples, ML enables predictive maintenance in industrial settings by forecasting equipment failures, optimizes energy usage in smart grids, and personalizes experiences in smart homes. However, integrating ML into IoT presents challenges, including data privacy, the need for real-time analytics, and managing vast data volumes. Advances in edge computing and federated learning are mitigating these issues by enabling local data processing and enhancing privacy, thus expanding the transformative potential of ML in IoT.

6. **Describe your process for reading and understanding a complex research paper like "A Survey of LLMs."**
> Reading an extensive review like 'A Survey of LLMs' allowed me to trace the evolution of language models from statistical LMs through neural and pre-training LMs to the pivotal role of LLMs. I appreciated the distinctive 'Large' feature of LLMs, which brings emergent and context-inference capabilities, delving into emblematic models like ChatGPT. Understanding the need for vast, curated datasets and the predominance of decoder-only architectures, including causal and prefix decoders, was enlightening. I also learned about fine-tuning strategies like instruction tuning and alignment tuning to enhance model performance and ethical alignment. The challenges I faced involved grasping these complex concepts in practice and synthesizing a large volume of information quickly. To overcome this, I engaged with LLMs like ChatGPT for practical insights and revisited reference materials highlighted in the papers. Additionally, organizing my learnings into notes has been crucial for reinforcing memory. Critically analyzing these advancements, applying insights to my work, and engaging with the AI community through discussions and collaborative projects have enriched my understanding and contributed to my growth in the field.

7. Discuss the potential applications of LLMs in cybersecurity.
> LLMs, with their advanced conversational capabilities, offer promising applications in cybersecurity. They could power chatbots that stay abreast of cutting-edge research within the cybersecurity community, enabling researchers to quickly catch up on and delve into the latest studies, thereby supporting their work. Additionally, LLMs can expedite the development process by translating researchers' ideas into code, facilitating training, validation, and refinement in specific scenarios. However, deep understanding of cybersecurity issues and derivation of complex mathematical formulas remain beyond LLM's current capabilities, highlighting the need for further advancements in LLM technology and the critical role of researchers' expertise. LLMs could also be utilized in identifying vulnerabilities, generating security patches, or enhancing training simulations. Integrating LLMs with other AI technologies or cybersecurity tools could further augment their utility, though ethical considerations and potential limitations must be rigorously managed to ensure responsible use and the reliability of outputs.

8. **How can attention mechanisms improve the performance of models in NLP tasks?**
> The cornerstone of attention mechanisms in NLP is the interplay of Query, Key, and Value, which enhances model performance by efficiently matching relevant information to the task at hand, based on the context's cues and the query's requirements. Prior to the advent of attention mechanisms, RNNs, even with advancements like GRU and LSTM, struggled with long sequence data due to inherent limitations in sequential processing and limited parallel computation capabilities. Attention mechanisms revolutionized this by enabling unparalleled parallel processing efficiency. Specifically, self-attention allows each token to directly relate to every other token, overcoming the sequential bottleneck. This foundation led to the transformer model, which quickly dominated NLP by significantly improving performance across a wide range of tasks, from machine translation to question-answering, owing to its ability to efficiently scale and process large datasets. Furthermore, attention mechanisms have enhanced model interpretability, allowing insights into model decision-making processes by visualizing focus areas within the data. This combination of scalability, efficiency, and interpretability underpins the transformative impact of attention mechanisms on NLP.

9. Explain the concept of explainability in LLMs and why it's important.
> 1) **Transparency:** Explainability in LLMs involves shedding light on the model's internal mechanisms. Given the complexity and the black-box nature of LLMs, achieving full transparency is challenging. However, efforts to make these models more interpretable focus on understanding the relationships and weights within the model that contribute to its decisions.  
> 2) **Feature Importance:** Techniques such as attention maps or feature attribution methods help identify which parts of the input data were most influential in the model's decision-making process. This is crucial for validating the model's reasoning and ensuring it aligns with logical and ethical considerations.
> 3) **Model Simplification:** Simplifying models by creating distilled or proxy models that approximate the behavior of LLMs can also aid in explainability. These simplified models are easier to analyze and can provide insights into how the original model operates.
> 4) **Interactive Explanation:** Some approaches involve creating interfaces that allow users to interact with the model, asking it to justify its outputs or to provide alternative outputs based on specific constraints. This interactive process helps users understand the model's reasoning.
> 5) **Ethical and Social Implications:** Explainability is directly linked to addressing bias, fairness, and ethical use of LLMs. Understanding how a model arrives at its conclusions can help identify and mitigate biases embedded within the training data or model architecture.

10. What strategies would you use to detect and mitigate malicious software in IoT devices?
> In my thesis project, I explored optimizing malware detection in IoT devices using ML technology by deploying models at the network layer to analyze traffic for malicious patterns. Malware activities, such as deployment, listening, and message transmission, generate distinctive traffic patterns that, if accurately identified by ML models, can facilitate effective learning and detection. However, challenges arise as malware employs techniques like traffic encryption and masquerading to evade detection, necessitating ongoing research. To address these challenges, a layered defense strategy encompassing device, application, and network levels, combined with continuous model learning and adaptation, is essential. Furthermore, integrating ML-based detection with existing security solutions and employing privacy-preserving data analysis can bolster IoT security. Collaboration across cybersecurity communities to share insights and threat intelligence is also crucial for refining detection capabilities and staying ahead of evolving malware threats.

### 聊天向

1.	你为什么要报考我们学校？

> 1) 我非常喜欢人工智能，在本科学习期间就了解了这个专业的相关内容并对此产生浓厚的兴趣，因此考研时义无反顾地选择了这个专业(专业喜好)
> 2) 我在了解专业相关的同时，也注意到国内对此有深远研究并作出成绩的院校不在少数。但是贵校在此方面的研究却与我的兴趣匹配度很高，而且也做出了很多傲人的成绩。(学校发展)
> 3) 在院校名气之外，我更看重的是贵校的科研实力，例如贵校在xx年到xx年在xx领域发表了xX论文，我深刻研读了论文并被深深震撼，我正是需要这种科研能力的培养与拔高。(科研能力)
> 4) 本学院xx教授在此专业的研究领域为xXX，这与我的兴趣方向不谋而合，而教授在此领域发表的相关论文更是让我认识到自己的才疏学浅，希望能够进入贵校跟着老师学习，争取在该领域更上一层楼。(导师研究方向 )

2.	解释下为何大学挂过科？

> 

3.	为何你的本科绩点不足满绩 70%?

> 

4.	四六级为何没过/低分擦线过？

>

5.	你对该专业研究方向有了解吗？

> 

6.	如果考上研究生你会读博吗？

> 

7.	你是否还在准备其他院校的复试？

> 

8.	为何你大学没有参加过竞赛、科研项目？

> 

9.	父母对你的学业的看法和态度？

> 

10.	有没有联系导师？意向导师？

> 

11.	对于“xx”热点你怎么看？

> 

12.	你有什么优点/缺点？

> 

13.	你能介绍下你的本科院校吗？

> 

14.	你觉得你的面试表现能通过吗？

> 