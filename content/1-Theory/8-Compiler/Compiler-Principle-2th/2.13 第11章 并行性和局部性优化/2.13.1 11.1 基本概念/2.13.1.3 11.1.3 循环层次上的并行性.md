### 11.1.3　循环层次上的并行性

循环是并行化的主要目标，在使用数组的应用中更是如此。运行时间较长的应用通常具有大型数组，从而产生具有很多迭代的循环。其中的每一个迭代处理数组中的一个元素。迭代之间相互独立的循环并不难找到。我们可以把这类循环的大量迭代分配给多个处理器。如果每个迭代的工作量基本相同，那么简单地在处理器之间平均分配迭代就可以得到最大的并行性。例11.1是一个特别简单的例子，它说明我们如何利用循环层次的并行性。

例11.1　下面的循环

![506-1](../Images/image04862.jpeg)

计算了向量X和Y的元素之间的平方差，并把它们存放到数组Z中。这个循环是可并行化的，因为每个迭代访问不同的数据集合。我们可以在具有M个处理器的计算机上执行这个循环。给每个处理器赋予唯一的ID p=0，1，2，…，M-1，并让每个处理器执行同样的代码：

![506-2](../Images/image04863.jpeg)

我们把这个循环中的迭代平均分配给各个处理器，第p个处理器被分配执行第p组迭代。请注意，迭代数目不一定能够被M整除，因此我们通过在程序中引入一个求最小值的运算来保证最后一个处理器执行的时候不会越过原来的循环界限。

任务层次的并行

有可能在一个循环的迭代之外找到并行性。比如，我们可以把两个不同的函数调用或两个独立的循环分配给两个处理器。这种形式的并行性称为任务并行性（task parallelism）。和循环层次的并行性相比，任务层次的并行性作为一个并行性来源的吸引力较弱。原因是对于每个程序来说，其独立任务的数量是固定的，并且不能随着数据大小的增加而增加。而一个典型循环的迭代次数则会随数据的增加而增加。不仅如此，这些任务的大小通常并不相等，因此难以让所有的处理器在所有时间都有事可做。

例11.1中显示的并行代码是一个SPMD（Single Program Multiple Data，单程序多数据）程序。所有的处理器都执行相同的代码，只是这些代码都带有各个处理器的唯一标识作为参数，因此不同的处理器完成不同的动作。通常会有一个被称为主处理器（master）的处理器来执行计算中的所有串行部分。在到达代码中已并行化的部分时，主处理器激活所有从处理器（slave）。所有从处理器同时执行代码中已经被并行化的区域。在每个并行化代码区域的尾部，所有这些处理器参与栅障同步（Barrier Synchronization）。只有等到所有处理器都已经执行完它们进入一个同步栅障之前的全部运算之后，各个处理器才会被允许离开这个栅障并执行栅障之后的运算。

如果我们只是把类似于例11.1中的简单循环并行化，那么得到的代码通常具有较低的并行性覆盖率和相对较细的并行性粒度。我们倾向于把一个程序的最外层循环并行化，因为这样会得到最粗的并行性粒度。比如，考虑二维FFT变换的应用，它在一个n×n的数据集上运行。这个程序对各行数据执行n次FFT变换，然后再对各列数据执行n次FFT变换。我们倾向于把n个独立FFT变换中的每一个分配给一个处理器，而不是使用多个处理器协作完成一次FFT变换。这样做使得代码容易书写，算法的并行性覆盖率达到100%，并且代码具有很好的数据局部性，因为在计算一个FFT时不需要进行任何通信。

很多应用没有可并行化的大的最外层循环。然而，这些应用的执行时间通常由耗时的内核决定。这些内核可能具有几百行代码，包含了不同嵌套层次的循环。有时可以单独地处理内核部分，通过集中考虑它的局部性，重新组织它的计算过程并把它分划成为多个独立的单元。