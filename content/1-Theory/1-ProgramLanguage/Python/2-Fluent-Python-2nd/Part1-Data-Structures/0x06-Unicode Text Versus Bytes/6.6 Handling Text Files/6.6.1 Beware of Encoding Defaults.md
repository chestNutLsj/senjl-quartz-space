## Beware of Encoding Defaults

Several settings affect the encoding defaults for I/O in Python. See the _default_encodings.py_ script in [Example 4-10](#ex_default_encodings).

##### Example 4-10. Exploring encoding defaults

```
import
```

The output of [Example 4-10](#ex_default_encodings) on GNU/Linux (Ubuntu 14.04 to 19.10) and macOS (10.9 to 10.14) is identical, showing that `UTF-8` is used everywhere in these systems:

$ python3 default_encodings.py
 locale.getpreferredencoding`()` -> `'UTF-8'`
                 type`(`my_file`)` -> <class `'_io.TextIOWrapper'`>
              my_file.encoding -> `'UTF-8'`
           sys.stdout.isatty`()` -> True
           sys.stdout.encoding -> `'utf-8'`
            sys.stdin.isatty`()` -> True
            sys.stdin.encoding -> `'utf-8'`
           sys.stderr.isatty`()` -> True
           sys.stderr.encoding -> `'utf-8'`
      sys.getdefaultencoding`()` -> `'utf-8'`
   sys.getfilesystemencoding`()` -> `'utf-8'`

On Windows, however, the output is [Example 4-11](#ex_default_encodings_ps).

##### Example 4-11. Default encodings on Windows 10 PowerShell (output is the same on cmd.exe)

```
>
```

[![^1]

`chcp` shows the active code page for the console: `437`.

[![^2]

Running _default_encodings.py_ with output to console.

[![^3]

`locale.getpreferredencoding()` is the most important setting.

[![^4]

Text files use `locale.getpreferredencoding()` by default.

[![^5]

The output is going to the console, so `sys.stdout.isatty()` is `True`.

[![^6]

Now, `sys.stdout.encoding` is not the same as the console code page reported by `chcp`!

Unicode support in Windows itself, and in Python for Windows, got better since I wrote the first edition of this book. [Example 4-11](#ex_default_encodings_ps) used to report four different encodings in Python 3.4 on Windows 7. The encodings for `stdout`, `stdin`, and `stderr` used to be the same as the active code page reported by the `chcp` command, but now they’re all `utf-8` thanks to [PEP 528—Change Windows console encoding to UTF-8](https://fpy.li/pep528) implemented in Python 3.6, and Unicode support in PowerShell in _cmd.exe_ (since Windows 1809 from October 2018).[^6] It’s weird that `chcp` and `sys.stdout.encoding` say different things when `stdout` is writing to the console, but it’s great that now we can print Unicode strings without encoding errors on Windows—unless the user redirects output to a file, as we’ll soon see. That does not mean all your favorite emojis will appear in the console: that also depends on the font the console is using.

Another change was [PEP 529—Change Windows filesystem encoding to UTF-8](https://fpy.li/pep529), also implemented in Python 3.6, which changed the filesystem encoding (used to represent names of directories and files) from Microsoft’s proprietary MBCS to UTF-8.

However, if the output of [Example 4-10](#ex_default_encodings) is redirected to a file, like this:

Z:`\>`python default_encodings.py > encodings.log

then, the value of `sys.stdout.isatty()` becomes `False`, and `sys.stdout.encoding` is set by `locale.getpreferredencoding()`, `'cp1252'` in that machine—but `sys.stdin.encoding` and `sys.stderr.encoding` remain `utf-8`.

###### Tip

In [Example 4-12](#ex_stdout_check) I use the `'\N{}'` escape for Unicode literals, where we write the official name of the character inside the `\N{}`. It’s rather verbose, but explicit and safe: Python raises `SyntaxError` if the name doesn’t exist—much better than writing a hex number that could be wrong, but you’ll only find out much later. You’d probably want to write a comment explaining the character codes anyway, so the verbosity of `\N{}` is easy to accept.

This means that a script like [Example 4-12](#ex_stdout_check) works when printing to the console, but may break when output is redirected to a file.

##### Example 4-12. stdout_check.py

```
import
```

[Example 4-12](#ex_stdout_check) displays the result of `sys.stdout.isatty()`, the value of `sys.​stdout.encoding`, and these three characters:

- `'…'` `HORIZONTAL ELLIPSIS`—exists in CP 1252 but not in CP 437.
    
- `'∞'` `INFINITY`—exists in CP 437 but not in CP 1252.
    
- `'㊷'` `CIRCLED NUMBER FORTY TWO`—doesn’t exist in CP 1252 or CP 437.
    

When I run _stdout_check.py_ on PowerShell or _cmd.exe_, it works as captured in [Figure 4-3](#fig_stdout_check).

![Screen capture of `stdout_check.py` on PowerShell](assets/flpy_0403.png)

###### Figure 4-3. Running _stdout_check.py_ on PowerShell.

Despite `chcp` reporting the active code as 437, `sys.stdout.encoding` is UTF-8, so the `HORIZONTAL ELLIPSIS` and `INFINITY` both output correctly. The `CIRCLED NUMBER FORTY TWO` is replaced by a rectangle, but no error is raised. Presumably it is recognized as a valid character, but the console font doesn’t have the glyph to display it.

However, when I redirect the output of _stdout_check.py_ to a file, I get [Figure 4-4](#fig_stdout_check_redir).

![Screen capture of `stdout_check.py` on PowerShell, redirecting output](assets/flpy_0404.png)

###### Figure 4-4. Running _stdout_check.py_ on PowerShell, redirecting output.

The first problem demonstrated by [Figure 4-4](#fig_stdout_check_redir) is the `UnicodeEncodeError` mentioning character `'\u221e'`, because `sys.stdout.encoding` is `'cp1252'`—a code page that doesn’t have the `INFINITY` character.

Reading _out.txt_ with the `type` command—or a Windows editor like VS Code or Sublime Text—shows that instead of HORIZONTAL ELLIPSIS, I got `'à'` (`LATIN SMALL LETTER A WITH GRAVE`). As it turns out, the byte value 0x85 in CP 1252 means `'…'`, but in CP 437 the same byte value represents `'à'`. So it seems the active code page does matter, not in a sensible or useful way, but as partial explanation of a bad Unicode experience.

###### Note

I used a laptop configured for the US market, running Windows 10 OEM to run these experiments. Windows versions localized for other countries may have different encoding configurations. For example, in Brazil the Windows console uses code page 850 by default—not 437.

To wrap up this maddening issue of default encodings, let’s give a final look at the different encodings in [Example 4-11](#ex_default_encodings_ps):

- If you omit the `encoding` argument when opening a file, the default is given by `locale.getpreferredencoding()` (`'cp1252'` in [Example 4-11](#ex_default_encodings_ps)).
    
- The encoding of `sys.stdout|stdin|stderr` used to be set by the [`PYTHONIOENCODING`](https://fpy.li/4-12) environment variable before Python 3.6—now that variable is ignored, unless [`PYTHONLEGACYWINDOWSSTDIO`](https://fpy.li/4-13) is set to a nonempty string. Otherwise, the encoding for standard I/O is UTF-8 for interactive I/O, or defined by `locale.getpreferredencoding()` if the output/input is redirected to/from a file.
    
- `sys.getdefaultencoding()` is used internally by Python in implicit conversions of binary data to/from `str`. Changing this setting is not supported.
    
- `sys.getfilesystemencoding()` is used to encode/decode filenames (not file contents). It is used when `open()` gets a `str` argument for the filename; if the filename is given as a `bytes` argument, it is passed unchanged to the OS API.
    

###### Note

On GNU/Linux and macOS, all of these encodings are set to UTF-8 by default, and have been for several years, so I/O handles all Unicode characters. On Windows, not only are different encodings used in the same system, but they are usually code pages like `'cp850'` or `'cp1252'` that support only ASCII, with 127 additional characters that are not the same from one encoding to the other. Therefore, Windows users are far more likely to face encoding errors unless they are extra careful.

To summarize, the most important encoding setting is that returned by `locale.getpreferredencoding()`: it is the default for opening text files and for `sys.stdout/stdin/stderr` when they are redirected to files. However, the [documentation](https://fpy.li/4-14) reads (in part):

> `locale.getpreferredencoding(do_setlocale=True)`
> 
> Return the encoding used for text data, according to user preferences. User preferences are expressed differently on different systems, and might not be available programmatically on some systems, so this function only returns a guess. […]

Therefore, the best advice about encoding defaults is: do not rely on them.

You will avoid a lot of pain if you follow the advice of the Unicode sandwich and always are explicit about the encodings in your programs. Unfortunately, Unicode is painful even if you get your `bytes` correctly converted to `str`. The next two sections cover subjects that are simple in ASCII-land, but get quite complex on planet Unicode: text normalization (i.e., converting text to a uniform representation for comparisons) and sorting.