## Downloading with concurrent.futures

The main features of the `concurrent.futures` package are the `ThreadPoolExecutor` and `ProcessPoolExecutor` classes, which implement an API to submit callables for execution in different threads or processes, respectively. The classes transparently manage a pool of worker threads or processes, and queues to distribute jobs and collect results. But the interface is very high-level, and we don’t need to know about any of those details for a simple use case like our flag downloads.

[Example 20-3](#flags_threadpool_ex) shows the easiest way to implement the downloads concurrently, using the `ThreadPoolExecutor.map` method.

##### Example 20-3. flags_threadpool.py: threaded download script using `futures.ThreadPoolExecutor`

```
from
```

[![^1]

Reuse some functions from the `flags` module ([Example 20-2](#flags_module_ex)).

[![^2]

Function to download a single image; this is what each worker will execute.

[![^3]

Instantiate the `ThreadPoolExecutor` as a context manager; the `executor​.__exit__` method will call `executor.shutdown(wait=True)`, which will block until all threads are done.

[![^4]

The `map` method is similar to the `map` built-in, except that the `download_one` function will be called concurrently from multiple threads; it returns a generator that you can iterate to retrieve the value returned by each function call—in this case, each call to `download_one` will return a country code.

[![^5]

Return the number of results obtained. If any of the threaded calls raises an exception, that exception is raised here when the implicit `next()` call inside the `list` constructor tries to retrieve the corresponding return value from the iterator returned by `executor.map`.

[![^6]

Call the `main` function from the `flags` module, passing the concurrent version of `download_many`.

Note that the `download_one` function from [Example 20-3](#flags_threadpool_ex) is essentially the body of the `for` loop in the `download_many` function from [Example 20-2](#flags_module_ex). This is a common refactoring when writing concurrent code: turning the body of a sequential `for` loop into a function to be called concurrently.

###### Tip

[Example 20-3](#flags_threadpool_ex) is very short because I was able to reuse most functions from the sequential _flags.py_ script. One of the best features of `concurrent.futures` is to make it simple to add concurrent execution on top of legacy sequential code.

The `ThreadPoolExecutor` constructor takes several arguments not shown, but the first and most important one is `max_workers`, setting the maximum number of worker threads to be executed. When `max_workers` is `None` (the default), `ThreadPool​Executor` decides its value using the following expression—since Python 3.8:

```
max_workers
```

The rationale is explained in the [`ThreadPoolExecutor` documentation](https://fpy.li/20-6):

> This default value preserves at least 5 workers for I/O bound tasks. It utilizes at most 32 CPU cores for CPU bound tasks which release the GIL. And it avoids using very large resources implicitly on many-core machines.
> 
> `ThreadPoolExecutor` now reuses idle worker threads before starting `max_workers` worker threads too.

To conclude: the computed default for `max_workers` is sensible, and `ThreadPoolExecutor` avoids starting new workers unnecessarily. Understanding the logic behind `max_workers` may help you decide when and how to set it yourself.

The library is called _concurrency.futures_, yet there are no futures to be seen in [Example 20-3](#flags_threadpool_ex), so you may be wondering where they are. The next section explains.