# Launching Processes with concurrent.futures

The [`concurrent.futures` documentation page](https://fpy.li/20-8) is subtitled “Launching parallel tasks.” The package enables parallel computation on multicore machines because it supports distributing work among multiple Python processes using the `ProcessPool​Executor` class.

Both `ProcessPoolExecutor` and `ThreadPoolExecutor` implement the [`Executor`](https://fpy.li/20-9) interface, so it’s easy to switch from a thread-based to a process-based solution using `concurrent.futures`.

There is no advantage in using a `ProcessPoolExecutor` for the flags download example or any I/O-bound job. It’s easy to verify this; just change these lines in [Example 20-3](#flags_threadpool_ex):

```
def
```

To this:

```
def
```

The constructor for `ProcessPoolExecutor` also has a `max_workers` parameter, which defaults to `None`. In that case, the executor limits the number of workers to the number returned by `os.cpu_count()`.

Processes use more memory and take longer to start than threads, so the real value of `ProcessPoolExecutor` is in CPU-intensive jobs. Let’s go back to the primality test example of [“A Homegrown Process Pool”](ch19.html#naive_multiprocessing_sec), rewriting it with `concurrent.futures`.