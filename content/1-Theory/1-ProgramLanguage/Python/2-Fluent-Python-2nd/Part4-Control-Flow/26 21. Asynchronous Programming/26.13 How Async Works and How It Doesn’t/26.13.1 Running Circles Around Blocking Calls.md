## Running Circles Around Blocking Calls

Ryan Dahl, the inventor of Node.js, introduces the philosophy of his project by saying “We’re doing I/O completely wrong.”[^19].

Table 21-1. Modern computer latency for reading data from different devices; third column shows proportional times in a scale easier to understand for us slow humans
|Device|CPU cycles|Proportional “human” scale|
|---|---|---|
|L1 cache|3|3 seconds|
|L2 cache|14|14 seconds|
|RAM|250|250 seconds|
|disk|41,000,000|1.3 years|
|network|240,000,000|7.6 years|

To make sense of [Table 21-1](#latency_tbl), bear in mind that modern CPUs with GHz clocks run billions of cycles per second. Let’s say that a CPU runs exactly 1 billion cycles per second. That CPU can make more than 333 million L1 cache reads in 1 second, or 4 (four!) network reads in the same time. The third column of [Table 21-1](#latency_tbl) puts those numbers in perspective by multiplying the second column by a constant factor. So, in an alternate universe, if one read from L1 cache took 3 seconds, then a network read would take 7.6 years!

[Table 21-1](#latency_tbl) explains why a disciplined approach to asynchronous programming can lead to high-performance servers. The challenge is achieving that discipline. The first step is to recognize that “I/O bound system” is a fantasy.