## Concurrency and Scalability Beyond Python

[_RabbitMQ in Action_](https://fpy.li/19-92) by Alvaro Videla and Jason J. W. Williams (Manning) is a very well-written introduction to _RabbitMQ_ and the Advanced Message Queuing Protocol (AMQP) standard, with examples in Python, PHP, and Ruby. Regardless of the rest of your tech stack, and even if you plan to use _Celery_ with _RabbitMQ_ under the hood, I recommend this book for its coverage of concepts, motivation, and patterns for distributed message queues, as well as operating and tuning _RabbitMQ_ at scale.

I learned a lot reading [_Seven Concurrency Models in Seven Weeks_](https://fpy.li/19-93), by Paul Butcher (Pragmatic Bookshelf), with the eloquent subtitle _When Threads Unravel_. Chapter 1 of the book presents the core concepts and challenges of programming with threads and locks in Java.[^28] about actors uses Scala and the Akka framework. Unless you already know Scala, Elixir is a more accessible language to learn and experiment with the actor model and the Erlang/OTP distributed systems platform.

Unmesh Joshi of Thoughtworks has contributed several pages documenting “Patterns of Distributed Systems” to Martin Fowler’s [blog](https://fpy.li/19-96). The [opening page](https://fpy.li/19-97) is a great introduction the topic, with links to individual patterns. Joshi is adding patterns incrementally, but what’s already there distills years of hard-earned experience in mission-critical systems.

Martin Kleppmann’s [_Designing Data-Intensive Applications_](https://fpy.li/19-98) (O’Reilly) is a rare book written by a practitioner with deep industry experience and advanced academic background. The author worked with large-scale data infrastructure at LinkedIn and two startups, before becoming a researcher of distributed systems at the University of Cambridge. Each chapter in Kleppmann’s book ends with an extensive list of references, including recent research results. The book also includes numerous illuminating diagrams and beautiful concept maps.

I was fortunate to be in the audience for Francesco Cesarini’s outstanding workshop on the architecture of reliable distributed systems at OSCON 2016: “Designing and architecting for scalability with Erlang/OTP” ([video](https://fpy.li/19-99) at the O’Reilly Learning Platform). Despite the title, 9:35 into the video, Cesarini explains:

> Very little of what I am going to say will be Erlang-specific […]. The fact remains that Erlang will remove a lot of accidental difficulties to making systems which are resilient and which never fail, and are scalable. So it will be much easier if you do use Erlang, or a language running on the Erlang virtual machine.

That workshop was based on the last four chapters of [_Designing for Scalability with Erlang/OTP_](https://fpy.li/19-100) by Francesco Cesarini and Steve Vinoski (O’Reilly).

Programming distributed systems is challenging and exciting, but beware of [_web-scale envy_](https://fpy.li/19-40). The [KISS principle](https://fpy.li/19-102) remains solid engineering advice.

Check out the paper [“Scalability! But at what COST?”](https://fpy.li/19-103) by Frank McSherry, Michael Isard, and Derek G. Murray. The authors identified parallel graph-processing systems presented in academic symposia that require hundreds of cores to outperform a “competent single-threaded implementation.” They also found systems that “underperform one thread for all of their reported configurations.”

Those findings remind me of a classic hacker quip:

> My Perl script is faster than your Hadoop cluster.

##### Soapbox

To Manage Complexity, We Need Constraints

I learned to program on a TI-58 calculator. Its “language” was similar to assembly. At that level, all “variables” are globals, and you don’t have the luxury of structured control flow statements. You have conditional jumps: instructions that take the execution directly to an arbitrary location—ahead or behind the current spot—depending on the value of a CPU register or flag.

Basically you can do anything in assembly, and that’s the challenge: there are very few constraints to keep you from making mistakes, and to help maintainers understand the code when changes are needed.

The second language I learned was the unstructured BASIC that came with 8-bit computers—nothing like Visual Basic, which appeared much later. There were `FOR`, `GOSUB`, and `RETURN` statements, but still no concept of local variables. `GOSUB` did not support parameter passing: it was just a fancy `GOTO` that put a return line number in a stack so that `RETURN` had a target to jump to. Subroutines could help themselves to the global data, and put results there too. We had to improvise other forms of control flow with combinations of `IF` and `GOTO`—which, again, allowed you to jump to any line of the program.

After a few years of programming with jumps and global variables, I remember the struggle to rewire my brain for “structured programming” when I learned Pascal. Now I had to use control flow statements around blocks of code that have a single entry point. I couldn’t jump to any instruction I liked. Global variables were unavoidable in BASIC, but now they were taboo. I needed to rethink the flow of data and explicitly pass arguments to functions.

The next challenge for me was learning object-oriented programming. At its core, object-oriented programming is structured programming with more constraints and polymorphism. Information hiding forces yet another rethink of where data lives. I remember being frustrated more than once because I had to refactor my code so that a method I was writing could get information that was encapsulated in an object that my method could not reach.

Functional programming languages add other constraints, but immutability is the hardest to swallow after decades of imperative programming and object-oriented programming. After we get used to these constraints, we see them as blessings. They make reasoning about the code much easier.

Lack of constraints is the main problem with the threads-and-locks model of concurrent programming. When summarizing Chapter 1 of _Seven Concurrency Models in Seven Weeks_, Paul Butcher wrote:

> The greatest weakness of the approach, however, is that threads-and-locks programming is _hard_. It may be easy for a language designer to add them to a language, but they provide us, the poor programmers, with very little help.

Some examples of unconstrained behavior in that model:

- Threads can share access to arbitrary, mutable data structures.
    
- The scheduler can interrupt a thread at almost any point, including in the middle of a simple operation like `a += 1`. Very few operations are atomic at the level of source code expressions.
    
- Locks are usually _advisory_. That’s a technical term meaning that you must remember to explicitly hold a lock before updating a shared data structure. If you forget to get the lock, nothing prevents your code from messing up the data while another thread dutifully holds the lock and is updating the same data.
    

In contrast, consider some constraints enforced by the actor model, in which the execution unit is called an _actor_:[^29]

- An actor can have internal state, but cannot share state with other actors.
    
- Actors can only communicate by sending and receiving messages.
    
- Messages only hold copies of data, not references to mutable data.
    
- An actor only handles one message at a time. There is no concurrent execution inside a single actor.
    

Of course, you can adopt an _actor style_ of coding in any language by following these rules. You can also use object-oriented programming idioms in C, and even structured programming patterns in assembly. But doing any of that requires a lot of agreement and discipline among everyone who touches the code.

Managing locks is unnecessary in the actor model, as implemented by Erlang and Elixir, where all data types are immutable.

Threads-and-locks are not going away. I just don’t think dealing with such low-level entities is a good use of my time as I write applications—as opposed to kernel modules or databases.

I reserve the right to change my mind, always. But right now, I am convinced that the actor model is the most sensible, general-purpose concurrent programming model available. CSP (Communicating Sequential Processes) is also sensible, but its implementation in Go leaves out some constraints. The idea in CSP is that coroutines (or _goroutines_ in Go) exchange data and synchronize using queues (called _channels_ in Go). But Go also supports memory sharing and locks. I’ve seen a book about Go advocate the use of shared memory and locks instead of channels—in the name of performance. Old habits die hard.

[^1]: .

[^2]:  was a pioneer of computer science in Brazil who made seminal contributions to Automata Theory and started the field of Tropical Mathematics. He was also an advocate of free software and free culture.

[^3]:  This section was suggested by my friend Bruce Eckel—author of books about Kotlin, Scala, Java, and C++.

[^4]: .

[^5]: .

[^6]: , who contributed the time-slicing GIL logic to Python 3.2.

[^7]: .

[^8]: .

[^9]:  for example. I used the ASCII characters `"\|/-"` to keep the examples simple.

[^10]: .

[^11]:  Thanks to tech reviewers Caleb Hattingh and Jürgen Gmach who did not let me overlook _greenlet_ and _gevent_.

[^12]:  It’s a 15” MacBook Pro 2018 with a 6-core, 2.2 GHz Intel Core i7 CPU.

[^13]:  This is true today because you are probably using a modern OS with _preemptive multitasking_. Windows before the NT era and macOS before the OSX era were not “preemptive,” therefore any process could take over 100% of the CPU and freeze the whole system. We are not completely free of this kind of problem today but trust this graybeard: this troubled every user in the 1990s, and a hard reset was the only cure.

[^14]:  In this example, `0` is a convenient sentinel. `None` is also commonly used for that. Using `0` simplifies the type hint for `PrimeResult` and the code for `worker`.

[^15]:  Surviving serialization without losing our identity is a pretty good life goal.

[^16]: .

[^17]:  in the English Wikipedia.

[^18]:  These are probably the same reasons that prompted the creator of the Ruby language, Yukihiro Matsumoto, to use a GIL in his interpreter as well.

[^19]:  As an exercise in college, I had to implement the LZW compression algorithm in C. But first I wrote it in Python, to check my understanding of the spec. The C version was about 900× faster.

[^20]: .

[^21]:  offer another type of HTTP cache, deployed in data centers closer to the end users of your application.

[^22]: .

[^23]:  Some speakers spell out the WSGI acronym, while others pronounce it as one word rhyming with “whisky.”

[^24]:  _uWSGI_ is spelled with a lowercase “u,” but that is pronounced as the Greek letter “µ,” so the whole name sounds like “micro-whisky” with a “g” instead of the “k.”

[^25]: . Highly recommended for users of _uWSGI_.

[^26]:  Caleb is one of the tech reviewers for this edition of _Fluent Python_.

[^27]:  Thanks to Lucas Brunialti for sending me a link to this talk.

[^28]:  Python’s `threading` and `concurrent.futures` APIs are heavily influenced by the Java standard library.

[^29]:  The Erlang community uses the term “process” for actors. In Erlang, each process is a function in its own loop, so they are very lightweight and it’s feasible to have millions of them active at once in a single machine—no relation to the heavyweight OS processes we’ve been talking about elsewhere in this chapter. So here we have examples of the two sins described by Prof. Simon: using different words to mean the same thing, and using one word to mean different things.