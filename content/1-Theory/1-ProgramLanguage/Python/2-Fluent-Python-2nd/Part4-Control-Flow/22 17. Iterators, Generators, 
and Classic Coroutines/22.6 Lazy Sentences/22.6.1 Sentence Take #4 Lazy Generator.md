## Sentence Take #4: Lazy Generator

The `Iterator` interface is designed to be lazy: `next(my_iterator)` yields one item at a time. The opposite of lazy is eager: lazy evaluation and eager evaluation are technical terms in programming language theory.

Our `Sentence` implementations so far have not been lazy because the `__init__` eagerly builds a list of all words in the text, binding it to the `self.words` attribute. This requires processing the entire text, and the list may use as much memory as the text itself (probably more; it depends on how many nonword characters are in the text). Most of this work will be in vain if the user only iterates over the first couple of words. If you wonder, “Is there a lazy way of doing this in Python?” the answer is often “Yes.”

The `re.finditer` function is a lazy version of `re.findall`. Instead of a list, `re.finditer` returns a generator yielding `re.MatchObject` instances on demand. If there are many matches, `re.finditer` saves a lot of memory. Using it, our third version of `Sentence` is now lazy: it only reads the next word from the text when it is needed. The code is in [Example 17-8](#ex_sentence3).

##### Example 17-8. sentence_gen2.py: `Sentence` implemented using a generator function calling the `re.finditer` generator function

```
import
```

[![^1]

No need to have a `words` list.

[![^2]

`finditer` builds an iterator over the matches of `RE_WORD` on `self.text`, yielding `MatchObject` instances.

[![^3]

`match.group()` extracts the matched text from the `MatchObject` instance.

Generators are a great shortcut, but the code can be made even more concise with a generator expression.