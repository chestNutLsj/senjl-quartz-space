---
url: https://pytorch.org/docs/stable/torch.html
title: torch â€” PyTorch 2.0 documentation
---
The torch package contains data structures for multi-dimensional tensors and defines mathematical operations over these tensors. Additionally, it provides many utilities for efficient serialization of Tensors and arbitrary types, and other useful utilities.

It has a CUDA counterpart, that enables you to run your tensor computations on an NVIDIA GPU with compute capability >= 3.0.

## Tensors

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor" title="torch.is_tensor"><code><span>is_tensor</span></code></a></p></td><td><p>Returns True if <cite>obj</cite> is a PyTorch tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.is_storage.html#torch.is_storage" title="torch.is_storage"><code><span>is_storage</span></code></a></p></td><td><p>Returns True if <cite>obj</cite> is a PyTorch storage object.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.is_complex.html#torch.is_complex" title="torch.is_complex"><code><span>is_complex</span></code></a></p></td><td><p>Returns True if the data type of <code><span>input</span></code> is a complex data type i.e., one of <code><span>torch.complex64</span></code>, and <code><span>torch.complex128</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.is_conj.html#torch.is_conj" title="torch.is_conj"><code><span>is_conj</span></code></a></p></td><td><p>Returns True if the <code><span>input</span></code> is a conjugated tensor, i.e. its conjugate bit is set to <cite>True</cite>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.is_floating_point.html#torch.is_floating_point" title="torch.is_floating_point"><code><span>is_floating_point</span></code></a></p></td><td><p>Returns True if the data type of <code><span>input</span></code> is a floating point data type i.e., one of <code><span>torch.float64</span></code>, <code><span>torch.float32</span></code>, <code><span>torch.float16</span></code>, and <code><span>torch.bfloat16</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.is_nonzero.html#torch.is_nonzero" title="torch.is_nonzero"><code><span>is_nonzero</span></code></a></p></td><td><p>Returns True if the <code><span>input</span></code> is a single element tensor which is not equal to zero after type conversions.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.set_default_dtype.html#torch.set_default_dtype" title="torch.set_default_dtype"><code><span>set_default_dtype</span></code></a></p></td><td><p>Sets the default floating point dtype to <code><span>d</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.get_default_dtype.html#torch.get_default_dtype" title="torch.get_default_dtype"><code><span>get_default_dtype</span></code></a></p></td><td><p>Get the current default floating point <a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype"><code><span>torch.dtype</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.set_default_device.html#torch.set_default_device" title="torch.set_default_device"><code><span>set_default_device</span></code></a></p></td><td><p>Sets the default <code><span>torch.Tensor</span></code> to be allocated on <code><span>device</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.set_default_tensor_type.html#torch.set_default_tensor_type" title="torch.set_default_tensor_type"><code><span>set_default_tensor_type</span></code></a></p></td><td><p>Sets the default <code><span>torch.Tensor</span></code> type to floating point tensor type <code><span>t</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.numel.html#torch.numel" title="torch.numel"><code><span>numel</span></code></a></p></td><td><p>Returns the total number of elements in the <code><span>input</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.set_printoptions.html#torch.set_printoptions" title="torch.set_printoptions"><code><span>set_printoptions</span></code></a></p></td><td><p>Set options for printing.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.set_flush_denormal.html#torch.set_flush_denormal" title="torch.set_flush_denormal"><code><span>set_flush_denormal</span></code></a></p></td><td><p>Disables denormal floating numbers on CPU.</p></td></tr></tbody></table>

### Creation Ops

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code><span>tensor</span></code></a></p></td><td><p>Constructs a tensor with no autograd history (also known as a "leaf tensor", see <a href="https://pytorch.org/docs/stable/notes/autograd.html"><span>Autograd mechanics</span></a>) by copying <code><span>data</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sparse_coo_tensor.html#torch.sparse_coo_tensor" title="torch.sparse_coo_tensor"><code><span>sparse_coo_tensor</span></code></a></p></td><td><p>Constructs a <a href="https://pytorch.org/docs/stable/sparse.html#sparse-coo-docs"><span>sparse tensor in COO(rdinate) format</span></a> with specified values at the given <code><span>indices</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sparse_csr_tensor.html#torch.sparse_csr_tensor" title="torch.sparse_csr_tensor"><code><span>sparse_csr_tensor</span></code></a></p></td><td><p>Constructs a <a href="https://pytorch.org/docs/stable/sparse.html#sparse-csr-docs"><span>sparse tensor in CSR (Compressed Sparse Row)</span></a> with specified values at the given <code><span>crow_indices</span></code> and <code><span>col_indices</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sparse_csc_tensor.html#torch.sparse_csc_tensor" title="torch.sparse_csc_tensor"><code><span>sparse_csc_tensor</span></code></a></p></td><td><p>Constructs a <a href="https://pytorch.org/docs/stable/sparse.html#sparse-csc-docs"><span>sparse tensor in CSC (Compressed Sparse Column)</span></a> with specified values at the given <code><span>ccol_indices</span></code> and <code><span>row_indices</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sparse_bsr_tensor.html#torch.sparse_bsr_tensor" title="torch.sparse_bsr_tensor"><code><span>sparse_bsr_tensor</span></code></a></p></td><td><p>Constructs a <a href="https://pytorch.org/docs/stable/sparse.html#sparse-bsr-docs"><span>sparse tensor in BSR (Block Compressed Sparse Row))</span></a> with specified 2-dimensional blocks at the given <code><span>crow_indices</span></code> and <code><span>col_indices</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sparse_bsc_tensor.html#torch.sparse_bsc_tensor" title="torch.sparse_bsc_tensor"><code><span>sparse_bsc_tensor</span></code></a></p></td><td><p>Constructs a <a href="https://pytorch.org/docs/stable/sparse.html#sparse-bsc-docs"><span>sparse tensor in BSC (Block Compressed Sparse Column))</span></a> with specified 2-dimensional blocks at the given <code><span>ccol_indices</span></code> and <code><span>row_indices</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.asarray.html#torch.asarray" title="torch.asarray"><code><span>asarray</span></code></a></p></td><td><p>Converts <code><span>obj</span></code> to a tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.as_tensor.html#torch.as_tensor" title="torch.as_tensor"><code><span>as_tensor</span></code></a></p></td><td><p>Converts <code><span>data</span></code> into a tensor, sharing data and preserving autograd history if possible.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided" title="torch.as_strided"><code><span>as_strided</span></code></a></p></td><td><p>Create a view of an existing <cite>torch.Tensor</cite> <code><span>input</span></code> with specified <code><span>size</span></code>, <code><span>stride</span></code> and <code><span>storage_offset</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.from_numpy.html#torch.from_numpy" title="torch.from_numpy"><code><span>from_numpy</span></code></a></p></td><td><p>Creates a <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><code><span>Tensor</span></code></a> from a <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.24)"><code><span>numpy.ndarray</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.from_dlpack.html#torch.from_dlpack" title="torch.from_dlpack"><code><span>from_dlpack</span></code></a></p></td><td><p>Converts a tensor from an external library into a <code><span>torch.Tensor</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.frombuffer.html#torch.frombuffer" title="torch.frombuffer"><code><span>frombuffer</span></code></a></p></td><td><p>Creates a 1-dimensional <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><code><span>Tensor</span></code></a> from an object that implements the Python buffer protocol.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros" title="torch.zeros"><code><span>zeros</span></code></a></p></td><td><p>Returns a tensor filled with the scalar value <cite>0</cite>, with the shape defined by the variable argument <code><span>size</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.zeros_like.html#torch.zeros_like" title="torch.zeros_like"><code><span>zeros_like</span></code></a></p></td><td><p>Returns a tensor filled with the scalar value <cite>0</cite>, with the same size as <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones"><code><span>ones</span></code></a></p></td><td><p>Returns a tensor filled with the scalar value <cite>1</cite>, with the shape defined by the variable argument <code><span>size</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.ones_like.html#torch.ones_like" title="torch.ones_like"><code><span>ones_like</span></code></a></p></td><td><p>Returns a tensor filled with the scalar value <cite>1</cite>, with the same size as <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange" title="torch.arange"><code><span>arange</span></code></a></p></td><td><p>Returns a 1-D tensor of size <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">âŒˆ</mo><mfrac><mrow><mtext>end</mtext><mo>âˆ’</mo><mtext>start</mtext></mrow><mtext>step</mtext></mfrac><mo fence="true">âŒ‰</mo></mrow><annotation encoding="application/x-tex">\left\lceil \frac{\text{end} - \text{start}}{\text{step}} \right\rceil</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span>âŒˆ</span></span><span><span></span><span><span><span><span><span><span></span><span><span><span><span>step</span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span><span>end</span></span><span>âˆ’</span><span><span>start</span></span></span></span></span></span><span>â€‹</span></span><span><span><span></span></span></span></span></span><span></span></span><span><span>âŒ‰</span></span></span></span></span></span></span> with values from the interval <code><span>[start,</span> <span>end)</span></code> taken with common difference <code><span>step</span></code> beginning from <cite>start</cite>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.range.html#torch.range" title="torch.range"><code><span>range</span></code></a></p></td><td><p>Returns a 1-D tensor of size <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo fence="true">âŒŠ</mo><mfrac><mrow><mtext>end</mtext><mo>âˆ’</mo><mtext>start</mtext></mrow><mtext>step</mtext></mfrac><mo fence="true">âŒ‹</mo></mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\left\lfloor \frac{\text{end} - \text{start}}{\text{step}} \right\rfloor + 1</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span>âŒŠ</span></span><span><span></span><span><span><span><span><span><span></span><span><span><span><span>step</span></span></span></span></span><span><span></span><span></span></span><span><span></span><span><span><span><span>end</span></span><span>âˆ’</span><span><span>start</span></span></span></span></span></span><span>â€‹</span></span><span><span><span></span></span></span></span></span><span></span></span><span><span>âŒ‹</span></span></span><span></span><span>+</span><span></span></span><span><span></span><span>1</span></span></span></span></span> with values from <code><span>start</span></code> to <code><span>end</span></code> with step <code><span>step</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.linspace.html#torch.linspace" title="torch.linspace"><code><span>linspace</span></code></a></p></td><td><p>Creates a one-dimensional tensor of size <code><span>steps</span></code> whose values are evenly spaced from <code><span>start</span></code> to <code><span>end</span></code>, inclusive.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.logspace.html#torch.logspace" title="torch.logspace"><code><span>logspace</span></code></a></p></td><td><p>Creates a one-dimensional tensor of size <code><span>steps</span></code> whose values are evenly spaced from <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mtext>base</mtext><mtext>start</mtext></msup></mrow><annotation encoding="application/x-tex">{{\text{{base}}}}^{{\text{{start}}}}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span>base</span></span></span></span></span><span><span><span><span><span><span></span><span><span><span><span><span><span>start</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> to <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mtext>base</mtext><mtext>end</mtext></msup></mrow><annotation encoding="application/x-tex">{{\text{{base}}}}^{{\text{{end}}}}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span><span><span><span>base</span></span></span></span></span><span><span><span><span><span><span></span><span><span><span><span><span><span>end</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>, inclusive, on a logarithmic scale with base <code><span>base</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.eye.html#torch.eye" title="torch.eye"><code><span>eye</span></code></a></p></td><td><p>Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.empty.html#torch.empty" title="torch.empty"><code><span>empty</span></code></a></p></td><td><p>Returns a tensor filled with uninitialized data.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.empty_like.html#torch.empty_like" title="torch.empty_like"><code><span>empty_like</span></code></a></p></td><td><p>Returns an uninitialized tensor with the same size as <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.empty_strided.html#torch.empty_strided" title="torch.empty_strided"><code><span>empty_strided</span></code></a></p></td><td><p>Creates a tensor with the specified <code><span>size</span></code> and <code><span>stride</span></code> and filled with undefined data.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.full.html#torch.full" title="torch.full"><code><span>full</span></code></a></p></td><td><p>Creates a tensor of size <code><span>size</span></code> filled with <code><span>fill_value</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.full_like.html#torch.full_like" title="torch.full_like"><code><span>full_like</span></code></a></p></td><td><p>Returns a tensor with the same size as <code><span>input</span></code> filled with <code><span>fill_value</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.quantize_per_tensor.html#torch.quantize_per_tensor" title="torch.quantize_per_tensor"><code><span>quantize_per_tensor</span></code></a></p></td><td><p>Converts a float tensor to a quantized tensor with given scale and zero point.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.quantize_per_channel.html#torch.quantize_per_channel" title="torch.quantize_per_channel"><code><span>quantize_per_channel</span></code></a></p></td><td><p>Converts a float tensor to a per-channel quantized tensor with given scales and zero points.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.dequantize.html#torch.dequantize" title="torch.dequantize"><code><span>dequantize</span></code></a></p></td><td><p>Returns an fp32 Tensor by dequantizing a quantized Tensor</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.complex.html#torch.complex" title="torch.complex"><code><span>complex</span></code></a></p></td><td><p>Constructs a complex tensor with its real part equal to <a href="https://pytorch.org/docs/stable/generated/torch.real.html#torch.real" title="torch.real"><code><span>real</span></code></a> and its imaginary part equal to <a href="https://pytorch.org/docs/stable/generated/torch.imag.html#torch.imag" title="torch.imag"><code><span>imag</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.polar.html#torch.polar" title="torch.polar"><code><span>polar</span></code></a></p></td><td><p>Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute value <a href="https://pytorch.org/docs/stable/generated/torch.abs.html#torch.abs" title="torch.abs"><code><span>abs</span></code></a> and angle <a href="https://pytorch.org/docs/stable/generated/torch.angle.html#torch.angle" title="torch.angle"><code><span>angle</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.heaviside.html#torch.heaviside" title="torch.heaviside"><code><span>heaviside</span></code></a></p></td><td><p>Computes the Heaviside step function for each element in <code><span>input</span></code>.</p></td></tr></tbody></table>

### Indexing, Slicing, Joining, Mutating Ops[](#indexing-slicing-joining-mutating-ops)

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.adjoint.html#torch.adjoint" title="torch.adjoint"><code><span>adjoint</span></code></a></p></td><td><p>Returns a view of the tensor conjugated and with the last two dimensions transposed.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.argwhere.html#torch.argwhere" title="torch.argwhere"><code><span>argwhere</span></code></a></p></td><td><p>Returns a tensor containing the indices of all non-zero elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat"><code><span>cat</span></code></a></p></td><td><p>Concatenates the given sequence of <code><span>seq</span></code> tensors in the given dimension.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.concat.html#torch.concat" title="torch.concat"><code><span>concat</span></code></a></p></td><td><p>Alias of <a href="https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat"><code><span>torch.cat()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.concatenate.html#torch.concatenate" title="torch.concatenate"><code><span>concatenate</span></code></a></p></td><td><p>Alias of <a href="https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat"><code><span>torch.cat()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.conj.html#torch.conj" title="torch.conj"><code><span>conj</span></code></a></p></td><td><p>Returns a view of <code><span>input</span></code> with a flipped conjugate bit.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.chunk.html#torch.chunk" title="torch.chunk"><code><span>chunk</span></code></a></p></td><td><p>Attempts to split a tensor into the specified number of chunks.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.dsplit.html#torch.dsplit" title="torch.dsplit"><code><span>dsplit</span></code></a></p></td><td><p>Splits <code><span>input</span></code>, a tensor with three or more dimensions, into multiple tensors depthwise according to <code><span>indices_or_sections</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.column_stack.html#torch.column_stack" title="torch.column_stack"><code><span>column_stack</span></code></a></p></td><td><p>Creates a new tensor by horizontally stacking the tensors in <code><span>tensors</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.dstack.html#torch.dstack" title="torch.dstack"><code><span>dstack</span></code></a></p></td><td><p>Stack tensors in sequence depthwise (along third axis).</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather" title="torch.gather"><code><span>gather</span></code></a></p></td><td><p>Gathers values along an axis specified by <cite>dim</cite>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.hsplit.html#torch.hsplit" title="torch.hsplit"><code><span>hsplit</span></code></a></p></td><td><p>Splits <code><span>input</span></code>, a tensor with one or more dimensions, into multiple tensors horizontally according to <code><span>indices_or_sections</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.hstack.html#torch.hstack" title="torch.hstack"><code><span>hstack</span></code></a></p></td><td><p>Stack tensors in sequence horizontally (column wise).</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.index_add.html#torch.index_add" title="torch.index_add"><code><span>index_add</span></code></a></p></td><td><p>See <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.index_add_.html#torch.Tensor.index_add_" title="torch.Tensor.index_add_"><code><span>index_add_()</span></code></a> for function description.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.index_copy.html#torch.index_copy" title="torch.index_copy"><code><span>index_copy</span></code></a></p></td><td><p>See <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.index_add_.html#torch.Tensor.index_add_" title="torch.Tensor.index_add_"><code><span>index_add_()</span></code></a> for function description.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.index_reduce.html#torch.index_reduce" title="torch.index_reduce"><code><span>index_reduce</span></code></a></p></td><td><p>See <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.index_reduce_.html#torch.Tensor.index_reduce_" title="torch.Tensor.index_reduce_"><code><span>index_reduce_()</span></code></a> for function description.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.index_select.html#torch.index_select" title="torch.index_select"><code><span>index_select</span></code></a></p></td><td><p>Returns a new tensor which indexes the <code><span>input</span></code> tensor along dimension <code><span>dim</span></code> using the entries in <code><span>index</span></code> which is a <cite>LongTensor</cite>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.masked_select.html#torch.masked_select" title="torch.masked_select"><code><span>masked_select</span></code></a></p></td><td><p>Returns a new 1-D tensor which indexes the <code><span>input</span></code> tensor according to the boolean mask <code><span>mask</span></code> which is a <cite>BoolTensor</cite>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.movedim.html#torch.movedim" title="torch.movedim"><code><span>movedim</span></code></a></p></td><td><p>Moves the dimension(s) of <code><span>input</span></code> at the position(s) in <code><span>source</span></code> to the position(s) in <code><span>destination</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.moveaxis.html#torch.moveaxis" title="torch.moveaxis"><code><span>moveaxis</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.movedim.html#torch.movedim" title="torch.movedim"><code><span>torch.movedim()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.narrow.html#torch.narrow" title="torch.narrow"><code><span>narrow</span></code></a></p></td><td><p>Returns a new tensor that is a narrowed version of <code><span>input</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.narrow_copy.html#torch.narrow_copy" title="torch.narrow_copy"><code><span>narrow_copy</span></code></a></p></td><td><p>Same as <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.narrow.html#torch.Tensor.narrow" title="torch.Tensor.narrow"><code><span>Tensor.narrow()</span></code></a> except this returns a copy rather than shared storage.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.nonzero.html#torch.nonzero" title="torch.nonzero"><code><span>nonzero</span></code></a></p></td><td></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.permute.html#torch.permute" title="torch.permute"><code><span>permute</span></code></a></p></td><td><p>Returns a view of the original tensor <code><span>input</span></code> with its dimensions permuted.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape" title="torch.reshape"><code><span>reshape</span></code></a></p></td><td><p>Returns a tensor with the same data and number of elements as <code><span>input</span></code>, but with the specified shape.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.row_stack.html#torch.row_stack" title="torch.row_stack"><code><span>row_stack</span></code></a></p></td><td><p>Alias of <a href="https://pytorch.org/docs/stable/generated/torch.vstack.html#torch.vstack" title="torch.vstack"><code><span>torch.vstack()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.select.html#torch.select" title="torch.select"><code><span>select</span></code></a></p></td><td><p>Slices the <code><span>input</span></code> tensor along the selected dimension at the given index.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.scatter.html#torch.scatter" title="torch.scatter"><code><span>scatter</span></code></a></p></td><td><p>Out-of-place version of <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code><span>torch.Tensor.scatter_()</span></code></a></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.diagonal_scatter.html#torch.diagonal_scatter" title="torch.diagonal_scatter"><code><span>diagonal_scatter</span></code></a></p></td><td><p>Embeds the values of the <code><span>src</span></code> tensor into <code><span>input</span></code> along the diagonal elements of <code><span>input</span></code>, with respect to <code><span>dim1</span></code> and <code><span>dim2</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.select_scatter.html#torch.select_scatter" title="torch.select_scatter"><code><span>select_scatter</span></code></a></p></td><td><p>Embeds the values of the <code><span>src</span></code> tensor into <code><span>input</span></code> at the given index.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.slice_scatter.html#torch.slice_scatter" title="torch.slice_scatter"><code><span>slice_scatter</span></code></a></p></td><td><p>Embeds the values of the <code><span>src</span></code> tensor into <code><span>input</span></code> at the given dimension.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.scatter_add.html#torch.scatter_add" title="torch.scatter_add"><code><span>scatter_add</span></code></a></p></td><td><p>Out-of-place version of <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_" title="torch.Tensor.scatter_add_"><code><span>torch.Tensor.scatter_add_()</span></code></a></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.scatter_reduce.html#torch.scatter_reduce" title="torch.scatter_reduce"><code><span>scatter_reduce</span></code></a></p></td><td><p>Out-of-place version of <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_reduce_.html#torch.Tensor.scatter_reduce_" title="torch.Tensor.scatter_reduce_"><code><span>torch.Tensor.scatter_reduce_()</span></code></a></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.split.html#torch.split" title="torch.split"><code><span>split</span></code></a></p></td><td><p>Splits the tensor into chunks.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.squeeze.html#torch.squeeze" title="torch.squeeze"><code><span>squeeze</span></code></a></p></td><td><p>Returns a tensor with all specified dimensions of <code><span>input</span></code> of size <cite>1</cite> removed.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.stack.html#torch.stack" title="torch.stack"><code><span>stack</span></code></a></p></td><td><p>Concatenates a sequence of tensors along a new dimension.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.swapaxes.html#torch.swapaxes" title="torch.swapaxes"><code><span>swapaxes</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose" title="torch.transpose"><code><span>torch.transpose()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.swapdims.html#torch.swapdims" title="torch.swapdims"><code><span>swapdims</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose" title="torch.transpose"><code><span>torch.transpose()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.t.html#torch.t" title="torch.t"><code><span>t</span></code></a></p></td><td><p>Expects <code><span>input</span></code> to be &lt;= 2-D tensor and transposes dimensions 0 and 1.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.take.html#torch.take" title="torch.take"><code><span>take</span></code></a></p></td><td><p>Returns a new tensor with the elements of <code><span>input</span></code> at the given indices.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.take_along_dim.html#torch.take_along_dim" title="torch.take_along_dim"><code><span>take_along_dim</span></code></a></p></td><td><p>Selects values from <code><span>input</span></code> at the 1-dimensional indices from <code><span>indices</span></code> along the given <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.tensor_split.html#torch.tensor_split" title="torch.tensor_split"><code><span>tensor_split</span></code></a></p></td><td><p>Splits a tensor into multiple sub-tensors, all of which are views of <code><span>input</span></code>, along dimension <code><span>dim</span></code> according to the indices or number of sections specified by <code><span>indices_or_sections</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.tile.html#torch.tile" title="torch.tile"><code><span>tile</span></code></a></p></td><td><p>Constructs a tensor by repeating the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose" title="torch.transpose"><code><span>transpose</span></code></a></p></td><td><p>Returns a tensor that is a transposed version of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.unbind.html#torch.unbind" title="torch.unbind"><code><span>unbind</span></code></a></p></td><td><p>Removes a tensor dimension.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.unsqueeze.html#torch.unsqueeze" title="torch.unsqueeze"><code><span>unsqueeze</span></code></a></p></td><td><p>Returns a new tensor with a dimension of size one inserted at the specified position.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.vsplit.html#torch.vsplit" title="torch.vsplit"><code><span>vsplit</span></code></a></p></td><td><p>Splits <code><span>input</span></code>, a tensor with two or more dimensions, into multiple tensors vertically according to <code><span>indices_or_sections</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.vstack.html#torch.vstack" title="torch.vstack"><code><span>vstack</span></code></a></p></td><td><p>Stack tensors in sequence vertically (row wise).</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.where.html#torch.where" title="torch.where"><code><span>where</span></code></a></p></td><td><p>Return a tensor of elements selected from either <code><span>input</span></code> or <code><span>other</span></code>, depending on <code><span>condition</span></code>.</p></td></tr></tbody></table>

## Generators[](#generators)

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator" title="torch.Generator"><code><span>Generator</span></code></a></p></td><td><p>Creates and returns a generator object that manages the state of the algorithm which produces pseudo random numbers.</p></td></tr></tbody></table>

## Random sampling[](#random-sampling)

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.seed.html#torch.seed" title="torch.seed"><code><span>seed</span></code></a></p></td><td><p>Sets the seed for generating random numbers to a non-deterministic random number.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed"><code><span>manual_seed</span></code></a></p></td><td><p>Sets the seed for generating random numbers.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.initial_seed.html#torch.initial_seed" title="torch.initial_seed"><code><span>initial_seed</span></code></a></p></td><td><p>Returns the initial seed for generating random numbers as a Python <cite>long</cite>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.get_rng_state.html#torch.get_rng_state" title="torch.get_rng_state"><code><span>get_rng_state</span></code></a></p></td><td><p>Returns the random number generator state as a <cite>torch.ByteTensor</cite>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.set_rng_state.html#torch.set_rng_state" title="torch.set_rng_state"><code><span>set_rng_state</span></code></a></p></td><td><p>Sets the random number generator state.</p></td></tr></tbody></table>

torch.default_generator _Returns the default CPU torch.Generator_[](#torch.torch.default_generator)

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.bernoulli.html#torch.bernoulli" title="torch.bernoulli"><code><span>bernoulli</span></code></a></p></td><td><p>Draws binary random numbers (0 or 1) from a Bernoulli distribution.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.multinomial.html#torch.multinomial" title="torch.multinomial"><code><span>multinomial</span></code></a></p></td><td><p>Returns a tensor where each row contains <code><span>num_samples</span></code> indices sampled from the multinomial probability distribution located in the corresponding row of tensor <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.normal.html#torch.normal" title="torch.normal"><code><span>normal</span></code></a></p></td><td><p>Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.poisson.html#torch.poisson" title="torch.poisson"><code><span>poisson</span></code></a></p></td><td><p>Returns a tensor of the same size as <code><span>input</span></code> with each element sampled from a Poisson distribution with rate parameter given by the corresponding element in <code><span>input</span></code> i.e.,</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand" title="torch.rand"><code><span>rand</span></code></a></p></td><td><p>Returns a tensor filled with random numbers from a uniform distribution on the interval <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">[0, 1)</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>[</span><span>0</span><span>,</span><span></span><span>1</span><span>)</span></span></span></span></span></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.rand_like.html#torch.rand_like" title="torch.rand_like"><code><span>rand_like</span></code></a></p></td><td><p>Returns a tensor with the same size as <code><span>input</span></code> that is filled with random numbers from a uniform distribution on the interval <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">[0, 1)</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>[</span><span>0</span><span>,</span><span></span><span>1</span><span>)</span></span></span></span></span>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.randint.html#torch.randint" title="torch.randint"><code><span>randint</span></code></a></p></td><td><p>Returns a tensor filled with random integers generated uniformly between <code><span>low</span></code> (inclusive) and <code><span>high</span></code> (exclusive).</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.randint_like.html#torch.randint_like" title="torch.randint_like"><code><span>randint_like</span></code></a></p></td><td><p>Returns a tensor with the same shape as Tensor <code><span>input</span></code> filled with random integers generated uniformly between <code><span>low</span></code> (inclusive) and <code><span>high</span></code> (exclusive).</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><code><span>randn</span></code></a></p></td><td><p>Returns a tensor filled with random numbers from a normal distribution with mean <cite>0</cite> and variance <cite>1</cite> (also called the standard normal distribution).</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.randn_like.html#torch.randn_like" title="torch.randn_like"><code><span>randn_like</span></code></a></p></td><td><p>Returns a tensor with the same size as <code><span>input</span></code> that is filled with random numbers from a normal distribution with mean 0 and variance 1.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.randperm.html#torch.randperm" title="torch.randperm"><code><span>randperm</span></code></a></p></td><td><p>Returns a random permutation of integers from <code><span>0</span></code> to <code><span>n</span> <span>-</span> <span>1</span></code>.</p></td></tr></tbody></table>

### In-place random sampling[](#in-place-random-sampling)

There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation:

*   [`torch.Tensor.bernoulli_()`](https://pytorch.org/docs/stable/generated/torch.Tensor.bernoulli_.html#torch.Tensor.bernoulli_ "torch.Tensor.bernoulli_") - in-place version of [`torch.bernoulli()`](https://pytorch.org/docs/stable/generated/torch.bernoulli.html#torch.bernoulli "torch.bernoulli")
    
*   [`torch.Tensor.cauchy_()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cauchy_.html#torch.Tensor.cauchy_ "torch.Tensor.cauchy_") - numbers drawn from the Cauchy distribution
    
*   [`torch.Tensor.exponential_()`](https://pytorch.org/docs/stable/generated/torch.Tensor.exponential_.html#torch.Tensor.exponential_ "torch.Tensor.exponential_") - numbers drawn from the exponential distribution
    
*   [`torch.Tensor.geometric_()`](https://pytorch.org/docs/stable/generated/torch.Tensor.geometric_.html#torch.Tensor.geometric_ "torch.Tensor.geometric_") - elements drawn from the geometric distribution
    
*   [`torch.Tensor.log_normal_()`](https://pytorch.org/docs/stable/generated/torch.Tensor.log_normal_.html#torch.Tensor.log_normal_ "torch.Tensor.log_normal_") - samples from the log-normal distribution
    
*   [`torch.Tensor.normal_()`](https://pytorch.org/docs/stable/generated/torch.Tensor.normal_.html#torch.Tensor.normal_ "torch.Tensor.normal_") - in-place version of [`torch.normal()`](https://pytorch.org/docs/stable/generated/torch.normal.html#torch.normal "torch.normal")
    
*   [`torch.Tensor.random_()`](https://pytorch.org/docs/stable/generated/torch.Tensor.random_.html#torch.Tensor.random_ "torch.Tensor.random_") - numbers sampled from the discrete uniform distribution
    
*   [`torch.Tensor.uniform_()`](https://pytorch.org/docs/stable/generated/torch.Tensor.uniform_.html#torch.Tensor.uniform_ "torch.Tensor.uniform_") - numbers sampled from the continuous uniform distribution
    

### Quasi-random sampling[](#quasi-random-sampling)

## Serialization[](#serialization)

## Parallelism[](#parallelism)

## Locally disabling gradient computation[](#locally-disabling-gradient-computation)

The context managers [`torch.no_grad()`](https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad "torch.no_grad"), [`torch.enable_grad()`](https://pytorch.org/docs/stable/generated/torch.enable_grad.html#torch.enable_grad "torch.enable_grad"), and [`torch.set_grad_enabled()`](https://pytorch.org/docs/stable/generated/torch.set_grad_enabled.html#torch.set_grad_enabled "torch.set_grad_enabled") are helpful for locally disabling and enabling gradient computation. See [Locally disabling gradient computation](https://pytorch.org/docs/stable/autograd.html#locally-disable-grad) for more details on their usage. These context managers are thread local, so they wonâ€™t work if you send work to another thread using the `threading` module, etc.

Examples:

```
>>> x = torch.zeros(1, requires_grad=True)
>>> with torch.no_grad():
...     y = x * 2
>>> y.requires_grad
False

>>> is_train = False
>>> with torch.set_grad_enabled(is_train):
...     y = x * 2
>>> y.requires_grad
False

>>> torch.set_grad_enabled(True)  # this can also be used as a function
>>> y = x * 2
>>> y.requires_grad
True

>>> torch.set_grad_enabled(False)
>>> y = x * 2
>>> y.requires_grad
False
```

## Math operations[](#math-operations)

### Pointwise Ops[](#pointwise-ops)

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.abs.html#torch.abs" title="torch.abs"><code><span>abs</span></code></a></p></td><td><p>Computes the absolute value of each element in <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.absolute.html#torch.absolute" title="torch.absolute"><code><span>absolute</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.abs.html#torch.abs" title="torch.abs"><code><span>torch.abs()</span></code></a></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.acos.html#torch.acos" title="torch.acos"><code><span>acos</span></code></a></p></td><td><p>Computes the inverse cosine of each element in <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.arccos.html#torch.arccos" title="torch.arccos"><code><span>arccos</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.acos.html#torch.acos" title="torch.acos"><code><span>torch.acos()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.acosh.html#torch.acosh" title="torch.acosh"><code><span>acosh</span></code></a></p></td><td><p>Returns a new tensor with the inverse hyperbolic cosine of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.arccosh.html#torch.arccosh" title="torch.arccosh"><code><span>arccosh</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.acosh.html#torch.acosh" title="torch.acosh"><code><span>torch.acosh()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.add.html#torch.add" title="torch.add"><code><span>add</span></code></a></p></td><td><p>Adds <code><span>other</span></code>, scaled by <code><span>alpha</span></code>, to <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.addcdiv.html#torch.addcdiv" title="torch.addcdiv"><code><span>addcdiv</span></code></a></p></td><td><p>Performs the element-wise division of <code><span>tensor1</span></code> by <code><span>tensor2</span></code>, multiplies the result by the scalar <code><span>value</span></code> and adds it to <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.addcmul.html#torch.addcmul" title="torch.addcmul"><code><span>addcmul</span></code></a></p></td><td><p>Performs the element-wise multiplication of <code><span>tensor1</span></code> by <code><span>tensor2</span></code>, multiplies the result by the scalar <code><span>value</span></code> and adds it to <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.angle.html#torch.angle" title="torch.angle"><code><span>angle</span></code></a></p></td><td><p>Computes the element-wise angle (in radians) of the given <code><span>input</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.asin.html#torch.asin" title="torch.asin"><code><span>asin</span></code></a></p></td><td><p>Returns a new tensor with the arcsine of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.arcsin.html#torch.arcsin" title="torch.arcsin"><code><span>arcsin</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.asin.html#torch.asin" title="torch.asin"><code><span>torch.asin()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.asinh.html#torch.asinh" title="torch.asinh"><code><span>asinh</span></code></a></p></td><td><p>Returns a new tensor with the inverse hyperbolic sine of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.arcsinh.html#torch.arcsinh" title="torch.arcsinh"><code><span>arcsinh</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.asinh.html#torch.asinh" title="torch.asinh"><code><span>torch.asinh()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.atan.html#torch.atan" title="torch.atan"><code><span>atan</span></code></a></p></td><td><p>Returns a new tensor with the arctangent of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.arctan.html#torch.arctan" title="torch.arctan"><code><span>arctan</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.atan.html#torch.atan" title="torch.atan"><code><span>torch.atan()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.atanh.html#torch.atanh" title="torch.atanh"><code><span>atanh</span></code></a></p></td><td><p>Returns a new tensor with the inverse hyperbolic tangent of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.arctanh.html#torch.arctanh" title="torch.arctanh"><code><span>arctanh</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.atanh.html#torch.atanh" title="torch.atanh"><code><span>torch.atanh()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.atan2.html#torch.atan2" title="torch.atan2"><code><span>atan2</span></code></a></p></td><td><p>Element-wise arctangent of <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>input</mtext><mi>i</mi></msub><mi mathvariant="normal">/</mi><msub><mtext>other</mtext><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{input}_{i} / \text{other}_{i}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span>input</span></span><span><span><span><span><span><span></span><span><span><span>i</span></span></span></span></span><span>â€‹</span></span><span><span><span></span></span></span></span></span></span><span>/</span><span><span><span>other</span></span><span><span><span><span><span><span></span><span><span><span>i</span></span></span></span></span><span>â€‹</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span> with consideration of the quadrant.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.arctan2.html#torch.arctan2" title="torch.arctan2"><code><span>arctan2</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.atan2.html#torch.atan2" title="torch.atan2"><code><span>torch.atan2()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.bitwise_not.html#torch.bitwise_not" title="torch.bitwise_not"><code><span>bitwise_not</span></code></a></p></td><td><p>Computes the bitwise NOT of the given input tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.bitwise_and.html#torch.bitwise_and" title="torch.bitwise_and"><code><span>bitwise_and</span></code></a></p></td><td><p>Computes the bitwise AND of <code><span>input</span></code> and <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.bitwise_or.html#torch.bitwise_or" title="torch.bitwise_or"><code><span>bitwise_or</span></code></a></p></td><td><p>Computes the bitwise OR of <code><span>input</span></code> and <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.bitwise_xor.html#torch.bitwise_xor" title="torch.bitwise_xor"><code><span>bitwise_xor</span></code></a></p></td><td><p>Computes the bitwise XOR of <code><span>input</span></code> and <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.bitwise_left_shift.html#torch.bitwise_left_shift" title="torch.bitwise_left_shift"><code><span>bitwise_left_shift</span></code></a></p></td><td><p>Computes the left arithmetic shift of <code><span>input</span></code> by <code><span>other</span></code> bits.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.bitwise_right_shift.html#torch.bitwise_right_shift" title="torch.bitwise_right_shift"><code><span>bitwise_right_shift</span></code></a></p></td><td><p>Computes the right arithmetic shift of <code><span>input</span></code> by <code><span>other</span></code> bits.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.ceil.html#torch.ceil" title="torch.ceil"><code><span>ceil</span></code></a></p></td><td><p>Returns a new tensor with the ceil of the elements of <code><span>input</span></code>, the smallest integer greater than or equal to each element.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.clamp.html#torch.clamp" title="torch.clamp"><code><span>clamp</span></code></a></p></td><td><p>Clamps all elements in <code><span>input</span></code> into the range <cite>[</cite> <a href="https://pytorch.org/docs/stable/generated/torch.min.html#torch.min" title="torch.min"><code><span>min</span></code></a>, <a href="https://pytorch.org/docs/stable/generated/torch.max.html#torch.max" title="torch.max"><code><span>max</span></code></a> <cite>]</cite>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.clip.html#torch.clip" title="torch.clip"><code><span>clip</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.clamp.html#torch.clamp" title="torch.clamp"><code><span>torch.clamp()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.conj_physical.html#torch.conj_physical" title="torch.conj_physical"><code><span>conj_physical</span></code></a></p></td><td><p>Computes the element-wise conjugate of the given <code><span>input</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.copysign.html#torch.copysign" title="torch.copysign"><code><span>copysign</span></code></a></p></td><td><p>Create a new floating-point tensor with the magnitude of <code><span>input</span></code> and the sign of <code><span>other</span></code>, elementwise.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cos.html#torch.cos" title="torch.cos"><code><span>cos</span></code></a></p></td><td><p>Returns a new tensor with the cosine of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cosh.html#torch.cosh" title="torch.cosh"><code><span>cosh</span></code></a></p></td><td><p>Returns a new tensor with the hyperbolic cosine of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.deg2rad.html#torch.deg2rad" title="torch.deg2rad"><code><span>deg2rad</span></code></a></p></td><td><p>Returns a new tensor with each of the elements of <code><span>input</span></code> converted from angles in degrees to radians.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.div.html#torch.div" title="torch.div"><code><span>div</span></code></a></p></td><td><p>Divides each element of the input <code><span>input</span></code> by the corresponding element of <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.divide.html#torch.divide" title="torch.divide"><code><span>divide</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.div.html#torch.div" title="torch.div"><code><span>torch.div()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.digamma.html#torch.digamma" title="torch.digamma"><code><span>digamma</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.digamma" title="torch.special.digamma"><code><span>torch.special.digamma()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.erf.html#torch.erf" title="torch.erf"><code><span>erf</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.erf" title="torch.special.erf"><code><span>torch.special.erf()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.erfc.html#torch.erfc" title="torch.erfc"><code><span>erfc</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.erfc" title="torch.special.erfc"><code><span>torch.special.erfc()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.erfinv.html#torch.erfinv" title="torch.erfinv"><code><span>erfinv</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.erfinv" title="torch.special.erfinv"><code><span>torch.special.erfinv()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.exp.html#torch.exp" title="torch.exp"><code><span>exp</span></code></a></p></td><td><p>Returns a new tensor with the exponential of the elements of the input tensor <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.exp2.html#torch.exp2" title="torch.exp2"><code><span>exp2</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.exp2" title="torch.special.exp2"><code><span>torch.special.exp2()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.expm1.html#torch.expm1" title="torch.expm1"><code><span>expm1</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.expm1" title="torch.special.expm1"><code><span>torch.special.expm1()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.fake_quantize_per_channel_affine.html#torch.fake_quantize_per_channel_affine" title="torch.fake_quantize_per_channel_affine"><code><span>fake_quantize_per_channel_affine</span></code></a></p></td><td><p>Returns a new tensor with the data in <code><span>input</span></code> fake quantized per channel using <code><span>scale</span></code>, <code><span>zero_point</span></code>, <code><span>quant_min</span></code> and <code><span>quant_max</span></code>, across the channel specified by <code><span>axis</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.fake_quantize_per_tensor_affine.html#torch.fake_quantize_per_tensor_affine" title="torch.fake_quantize_per_tensor_affine"><code><span>fake_quantize_per_tensor_affine</span></code></a></p></td><td><p>Returns a new tensor with the data in <code><span>input</span></code> fake quantized using <code><span>scale</span></code>, <code><span>zero_point</span></code>, <code><span>quant_min</span></code> and <code><span>quant_max</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.fix.html#torch.fix" title="torch.fix"><code><span>fix</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.trunc.html#torch.trunc" title="torch.trunc"><code><span>torch.trunc()</span></code></a></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.float_power.html#torch.float_power" title="torch.float_power"><code><span>float_power</span></code></a></p></td><td><p>Raises <code><span>input</span></code> to the power of <code><span>exponent</span></code>, elementwise, in double precision.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.floor.html#torch.floor" title="torch.floor"><code><span>floor</span></code></a></p></td><td><p>Returns a new tensor with the floor of the elements of <code><span>input</span></code>, the largest integer less than or equal to each element.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.floor_divide.html#torch.floor_divide" title="torch.floor_divide"><code><span>floor_divide</span></code></a></p></td><td></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.fmod.html#torch.fmod" title="torch.fmod"><code><span>fmod</span></code></a></p></td><td><p>Applies C++'s <a href="https://en.cppreference.com/w/cpp/numeric/math/fmod">std::fmod</a> entrywise.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.frac.html#torch.frac" title="torch.frac"><code><span>frac</span></code></a></p></td><td><p>Computes the fractional portion of each element in <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.frexp.html#torch.frexp" title="torch.frexp"><code><span>frexp</span></code></a></p></td><td><p>Decomposes <code><span>input</span></code> into mantissa and exponent tensors such that <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>=</mo><mtext>mantissa</mtext><mo>Ã—</mo><msup><mn>2</mn><mtext>exponent</mtext></msup></mrow><annotation encoding="application/x-tex">\text{input} = \text{mantissa} \times 2^{\text{exponent}}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>input</span></span><span></span><span>=</span><span></span></span><span><span></span><span><span>mantissa</span></span><span></span><span>Ã—</span><span></span></span><span><span></span><span><span>2</span><span><span><span><span><span><span></span><span><span><span><span>exponent</span></span></span></span></span></span></span></span></span></span></span></span></span></span>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.gradient.html#torch.gradient" title="torch.gradient"><code><span>gradient</span></code></a></p></td><td><p>Estimates the gradient of a function <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>:</mo><msup><mi mathvariant="double-struck">R</mi><mi>n</mi></msup><mo>â†’</mo><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">g : \mathbb{R}^n \rightarrow \mathbb{R}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>g</span><span></span><span>:</span><span></span></span><span><span></span><span><span>R</span><span><span><span><span><span><span></span><span><span>n</span></span></span></span></span></span></span></span><span></span><span>â†’</span><span></span></span><span><span></span><span>R</span></span></span></span></span> in one or more dimensions using the <a href="https://www.ams.org/journals/mcom/1988-51-184/S0025-5718-1988-0935077-0/S0025-5718-1988-0935077-0.pdf">second-order accurate central differences method</a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.imag.html#torch.imag" title="torch.imag"><code><span>imag</span></code></a></p></td><td><p>Returns a new tensor containing imaginary values of the <code><span>self</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.ldexp.html#torch.ldexp" title="torch.ldexp"><code><span>ldexp</span></code></a></p></td><td><p>Multiplies <code><span>input</span></code> by 2 ** <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.lerp.html#torch.lerp" title="torch.lerp"><code><span>lerp</span></code></a></p></td><td><p>Does a linear interpolation of two tensors <code><span>start</span></code> (given by <code><span>input</span></code>) and <code><span>end</span></code> based on a scalar or tensor <code><span>weight</span></code> and returns the resulting <code><span>out</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.lgamma.html#torch.lgamma" title="torch.lgamma"><code><span>lgamma</span></code></a></p></td><td><p>Computes the natural logarithm of the absolute value of the gamma function on <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.log.html#torch.log" title="torch.log"><code><span>log</span></code></a></p></td><td><p>Returns a new tensor with the natural logarithm of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.log10.html#torch.log10" title="torch.log10"><code><span>log10</span></code></a></p></td><td><p>Returns a new tensor with the logarithm to the base 10 of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.log1p.html#torch.log1p" title="torch.log1p"><code><span>log1p</span></code></a></p></td><td><p>Returns a new tensor with the natural logarithm of (1 + <code><span>input</span></code>).</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.log2.html#torch.log2" title="torch.log2"><code><span>log2</span></code></a></p></td><td><p>Returns a new tensor with the logarithm to the base 2 of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.logaddexp.html#torch.logaddexp" title="torch.logaddexp"><code><span>logaddexp</span></code></a></p></td><td><p>Logarithm of the sum of exponentiations of the inputs.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.logaddexp2.html#torch.logaddexp2" title="torch.logaddexp2"><code><span>logaddexp2</span></code></a></p></td><td><p>Logarithm of the sum of exponentiations of the inputs in base-2.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.logical_and.html#torch.logical_and" title="torch.logical_and"><code><span>logical_and</span></code></a></p></td><td><p>Computes the element-wise logical AND of the given input tensors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.logical_not.html#torch.logical_not" title="torch.logical_not"><code><span>logical_not</span></code></a></p></td><td><p>Computes the element-wise logical NOT of the given input tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.logical_or.html#torch.logical_or" title="torch.logical_or"><code><span>logical_or</span></code></a></p></td><td><p>Computes the element-wise logical OR of the given input tensors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.logical_xor.html#torch.logical_xor" title="torch.logical_xor"><code><span>logical_xor</span></code></a></p></td><td><p>Computes the element-wise logical XOR of the given input tensors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.logit.html#torch.logit" title="torch.logit"><code><span>logit</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.logit" title="torch.special.logit"><code><span>torch.special.logit()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.hypot.html#torch.hypot" title="torch.hypot"><code><span>hypot</span></code></a></p></td><td><p>Given the legs of a right triangle, return its hypotenuse.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.i0.html#torch.i0" title="torch.i0"><code><span>i0</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.i0" title="torch.special.i0"><code><span>torch.special.i0()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.igamma.html#torch.igamma" title="torch.igamma"><code><span>igamma</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.gammainc" title="torch.special.gammainc"><code><span>torch.special.gammainc()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.igammac.html#torch.igammac" title="torch.igammac"><code><span>igammac</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.gammaincc" title="torch.special.gammaincc"><code><span>torch.special.gammaincc()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul" title="torch.mul"><code><span>mul</span></code></a></p></td><td><p>Multiplies <code><span>input</span></code> by <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.multiply.html#torch.multiply" title="torch.multiply"><code><span>multiply</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul" title="torch.mul"><code><span>torch.mul()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.mvlgamma.html#torch.mvlgamma" title="torch.mvlgamma"><code><span>mvlgamma</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.multigammaln" title="torch.special.multigammaln"><code><span>torch.special.multigammaln()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num" title="torch.nan_to_num"><code><span>nan_to_num</span></code></a></p></td><td><p>Replaces <code><span>NaN</span></code>, positive infinity, and negative infinity values in <code><span>input</span></code> with the values specified by <code><span>nan</span></code>, <code><span>posinf</span></code>, and <code><span>neginf</span></code>, respectively.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.neg.html#torch.neg" title="torch.neg"><code><span>neg</span></code></a></p></td><td><p>Returns a new tensor with the negative of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.negative.html#torch.negative" title="torch.negative"><code><span>negative</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.neg.html#torch.neg" title="torch.neg"><code><span>torch.neg()</span></code></a></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.nextafter.html#torch.nextafter" title="torch.nextafter"><code><span>nextafter</span></code></a></p></td><td><p>Return the next floating-point value after <code><span>input</span></code> towards <code><span>other</span></code>, elementwise.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.polygamma.html#torch.polygamma" title="torch.polygamma"><code><span>polygamma</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.polygamma" title="torch.special.polygamma"><code><span>torch.special.polygamma()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.positive.html#torch.positive" title="torch.positive"><code><span>positive</span></code></a></p></td><td><p>Returns <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.pow.html#torch.pow" title="torch.pow"><code><span>pow</span></code></a></p></td><td><p>Takes the power of each element in <code><span>input</span></code> with <code><span>exponent</span></code> and returns a tensor with the result.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.quantized_batch_norm.html#torch.quantized_batch_norm" title="torch.quantized_batch_norm"><code><span>quantized_batch_norm</span></code></a></p></td><td><p>Applies batch normalization on a 4D (NCHW) quantized tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.quantized_max_pool1d.html#torch.quantized_max_pool1d" title="torch.quantized_max_pool1d"><code><span>quantized_max_pool1d</span></code></a></p></td><td><p>Applies a 1D max pooling over an input quantized tensor composed of several input planes.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.quantized_max_pool2d.html#torch.quantized_max_pool2d" title="torch.quantized_max_pool2d"><code><span>quantized_max_pool2d</span></code></a></p></td><td><p>Applies a 2D max pooling over an input quantized tensor composed of several input planes.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.rad2deg.html#torch.rad2deg" title="torch.rad2deg"><code><span>rad2deg</span></code></a></p></td><td><p>Returns a new tensor with each of the elements of <code><span>input</span></code> converted from angles in radians to degrees.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.real.html#torch.real" title="torch.real"><code><span>real</span></code></a></p></td><td><p>Returns a new tensor containing real values of the <code><span>self</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.reciprocal.html#torch.reciprocal" title="torch.reciprocal"><code><span>reciprocal</span></code></a></p></td><td><p>Returns a new tensor with the reciprocal of the elements of <code><span>input</span></code></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.remainder.html#torch.remainder" title="torch.remainder"><code><span>remainder</span></code></a></p></td><td><p>Computes <a href="https://docs.python.org/3/reference/expressions.html#binary-arithmetic-operations">Python's modulus operation</a> entrywise.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.round.html#torch.round" title="torch.round"><code><span>round</span></code></a></p></td><td><p>Rounds elements of <code><span>input</span></code> to the nearest integer.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.rsqrt.html#torch.rsqrt" title="torch.rsqrt"><code><span>rsqrt</span></code></a></p></td><td><p>Returns a new tensor with the reciprocal of the square-root of each of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sigmoid.html#torch.sigmoid" title="torch.sigmoid"><code><span>sigmoid</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.expit" title="torch.special.expit"><code><span>torch.special.expit()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sign.html#torch.sign" title="torch.sign"><code><span>sign</span></code></a></p></td><td><p>Returns a new tensor with the signs of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sgn.html#torch.sgn" title="torch.sgn"><code><span>sgn</span></code></a></p></td><td><p>This function is an extension of torch.sign() to complex tensors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.signbit.html#torch.signbit" title="torch.signbit"><code><span>signbit</span></code></a></p></td><td><p>Tests if each element of <code><span>input</span></code> has its sign bit set or not.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sin.html#torch.sin" title="torch.sin"><code><span>sin</span></code></a></p></td><td><p>Returns a new tensor with the sine of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sinc.html#torch.sinc" title="torch.sinc"><code><span>sinc</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.sinc" title="torch.special.sinc"><code><span>torch.special.sinc()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sinh.html#torch.sinh" title="torch.sinh"><code><span>sinh</span></code></a></p></td><td><p>Returns a new tensor with the hyperbolic sine of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.softmax.html#torch.softmax" title="torch.softmax"><code><span>softmax</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax"><code><span>torch.nn.functional.softmax()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sqrt.html#torch.sqrt" title="torch.sqrt"><code><span>sqrt</span></code></a></p></td><td><p>Returns a new tensor with the square-root of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.square.html#torch.square" title="torch.square"><code><span>square</span></code></a></p></td><td><p>Returns a new tensor with the square of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sub.html#torch.sub" title="torch.sub"><code><span>sub</span></code></a></p></td><td><p>Subtracts <code><span>other</span></code>, scaled by <code><span>alpha</span></code>, from <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.subtract.html#torch.subtract" title="torch.subtract"><code><span>subtract</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.sub.html#torch.sub" title="torch.sub"><code><span>torch.sub()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.tan.html#torch.tan" title="torch.tan"><code><span>tan</span></code></a></p></td><td><p>Returns a new tensor with the tangent of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.tanh.html#torch.tanh" title="torch.tanh"><code><span>tanh</span></code></a></p></td><td><p>Returns a new tensor with the hyperbolic tangent of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.true_divide.html#torch.true_divide" title="torch.true_divide"><code><span>true_divide</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.div.html#torch.div" title="torch.div"><code><span>torch.div()</span></code></a> with <code><span>rounding_mode=None</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.trunc.html#torch.trunc" title="torch.trunc"><code><span>trunc</span></code></a></p></td><td><p>Returns a new tensor with the truncated integer values of the elements of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.xlogy.html#torch.xlogy" title="torch.xlogy"><code><span>xlogy</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/special.html#torch.special.xlogy" title="torch.special.xlogy"><code><span>torch.special.xlogy()</span></code></a>.</p></td></tr></tbody></table>

### Reduction Ops[](#reduction-ops)

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.argmax.html#torch.argmax" title="torch.argmax"><code><span>argmax</span></code></a></p></td><td><p>Returns the indices of the maximum value of all elements in the <code><span>input</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.argmin.html#torch.argmin" title="torch.argmin"><code><span>argmin</span></code></a></p></td><td><p>Returns the indices of the minimum value(s) of the flattened tensor or along a dimension</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.amax.html#torch.amax" title="torch.amax"><code><span>amax</span></code></a></p></td><td><p>Returns the maximum value of each slice of the <code><span>input</span></code> tensor in the given dimension(s) <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.amin.html#torch.amin" title="torch.amin"><code><span>amin</span></code></a></p></td><td><p>Returns the minimum value of each slice of the <code><span>input</span></code> tensor in the given dimension(s) <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.aminmax.html#torch.aminmax" title="torch.aminmax"><code><span>aminmax</span></code></a></p></td><td><p>Computes the minimum and maximum values of the <code><span>input</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.all.html#torch.all" title="torch.all"><code><span>all</span></code></a></p></td><td><p>Tests if all elements in <code><span>input</span></code> evaluate to <cite>True</cite>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.any.html#torch.any" title="torch.any"><code><span>any</span></code></a></p></td><td><p>Tests if any element in <code><span>input</span></code> evaluates to <cite>True</cite>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.max.html#torch.max" title="torch.max"><code><span>max</span></code></a></p></td><td><p>Returns the maximum value of all elements in the <code><span>input</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.min.html#torch.min" title="torch.min"><code><span>min</span></code></a></p></td><td><p>Returns the minimum value of all elements in the <code><span>input</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.dist.html#torch.dist" title="torch.dist"><code><span>dist</span></code></a></p></td><td><p>Returns the p-norm of (<code><span>input</span></code> - <code><span>other</span></code>)</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.logsumexp.html#torch.logsumexp" title="torch.logsumexp"><code><span>logsumexp</span></code></a></p></td><td><p>Returns the log of summed exponentials of each row of the <code><span>input</span></code> tensor in the given dimension <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.mean.html#torch.mean" title="torch.mean"><code><span>mean</span></code></a></p></td><td><p>Returns the mean value of all elements in the <code><span>input</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.nanmean.html#torch.nanmean" title="torch.nanmean"><code><span>nanmean</span></code></a></p></td><td><p>Computes the mean of all <cite>non-NaN</cite> elements along the specified dimensions.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.median.html#torch.median" title="torch.median"><code><span>median</span></code></a></p></td><td><p>Returns the median of the values in <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.nanmedian.html#torch.nanmedian" title="torch.nanmedian"><code><span>nanmedian</span></code></a></p></td><td><p>Returns the median of the values in <code><span>input</span></code>, ignoring <code><span>NaN</span></code> values.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode" title="torch.mode"><code><span>mode</span></code></a></p></td><td><p>Returns a namedtuple <code><span>(values,</span> <span>indices)</span></code> where <code><span>values</span></code> is the mode value of each row of the <code><span>input</span></code> tensor in the given dimension <code><span>dim</span></code>, i.e. a value which appears most often in that row, and <code><span>indices</span></code> is the index location of each mode value found.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm" title="torch.norm"><code><span>norm</span></code></a></p></td><td><p>Returns the matrix norm or vector norm of a given tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.nansum.html#torch.nansum" title="torch.nansum"><code><span>nansum</span></code></a></p></td><td><p>Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.prod.html#torch.prod" title="torch.prod"><code><span>prod</span></code></a></p></td><td><p>Returns the product of all elements in the <code><span>input</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.quantile.html#torch.quantile" title="torch.quantile"><code><span>quantile</span></code></a></p></td><td><p>Computes the q-th quantiles of each row of the <code><span>input</span></code> tensor along the dimension <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.nanquantile.html#torch.nanquantile" title="torch.nanquantile"><code><span>nanquantile</span></code></a></p></td><td><p>This is a variant of <a href="https://pytorch.org/docs/stable/generated/torch.quantile.html#torch.quantile" title="torch.quantile"><code><span>torch.quantile()</span></code></a> that "ignores" <code><span>NaN</span></code> values, computing the quantiles <code><span>q</span></code> as if <code><span>NaN</span></code> values in <code><span>input</span></code> did not exist.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.std.html#torch.std" title="torch.std"><code><span>std</span></code></a></p></td><td><p>Calculates the standard deviation over the dimensions specified by <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.std_mean.html#torch.std_mean" title="torch.std_mean"><code><span>std_mean</span></code></a></p></td><td><p>Calculates the standard deviation and mean over the dimensions specified by <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sum.html#torch.sum" title="torch.sum"><code><span>sum</span></code></a></p></td><td><p>Returns the sum of all elements in the <code><span>input</span></code> tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.unique.html#torch.unique" title="torch.unique"><code><span>unique</span></code></a></p></td><td><p>Returns the unique elements of the input tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.unique_consecutive.html#torch.unique_consecutive" title="torch.unique_consecutive"><code><span>unique_consecutive</span></code></a></p></td><td><p>Eliminates all but the first element from every consecutive group of equivalent elements.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.var.html#torch.var" title="torch.var"><code><span>var</span></code></a></p></td><td><p>Calculates the variance over the dimensions specified by <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.var_mean.html#torch.var_mean" title="torch.var_mean"><code><span>var_mean</span></code></a></p></td><td><p>Calculates the variance and mean over the dimensions specified by <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.count_nonzero.html#torch.count_nonzero" title="torch.count_nonzero"><code><span>count_nonzero</span></code></a></p></td><td><p>Counts the number of non-zero values in the tensor <code><span>input</span></code> along the given <code><span>dim</span></code>.</p></td></tr></tbody></table>

### Comparison Ops[](#comparison-ops)

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="torch.allclose"><code><span>allclose</span></code></a></p></td><td><p>This function checks if <code><span>input</span></code> and <code><span>other</span></code> satisfy the condition:</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.argsort.html#torch.argsort" title="torch.argsort"><code><span>argsort</span></code></a></p></td><td><p>Returns the indices that sort a tensor along a given dimension in ascending order by value.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.eq.html#torch.eq" title="torch.eq"><code><span>eq</span></code></a></p></td><td><p>Computes element-wise equality</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.equal.html#torch.equal" title="torch.equal"><code><span>equal</span></code></a></p></td><td><p><code><span>True</span></code> if two tensors have the same size and elements, <code><span>False</span></code> otherwise.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.ge.html#torch.ge" title="torch.ge"><code><span>ge</span></code></a></p></td><td><p>Computes <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>â‰¥</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} \geq \text{other}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>input</span></span><span></span><span>â‰¥</span><span></span></span><span><span></span><span><span>other</span></span></span></span></span></span> element-wise.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.greater_equal.html#torch.greater_equal" title="torch.greater_equal"><code><span>greater_equal</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.ge.html#torch.ge" title="torch.ge"><code><span>torch.ge()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.gt.html#torch.gt" title="torch.gt"><code><span>gt</span></code></a></p></td><td><p>Computes <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>&gt;</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} &gt; \text{other}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>input</span></span><span></span><span>&gt;</span><span></span></span><span><span></span><span><span>other</span></span></span></span></span></span> element-wise.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.greater.html#torch.greater" title="torch.greater"><code><span>greater</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.gt.html#torch.gt" title="torch.gt"><code><span>torch.gt()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.isclose.html#torch.isclose" title="torch.isclose"><code><span>isclose</span></code></a></p></td><td><p>Returns a new tensor with boolean elements representing if each element of <code><span>input</span></code> is "close" to the corresponding element of <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.isfinite.html#torch.isfinite" title="torch.isfinite"><code><span>isfinite</span></code></a></p></td><td><p>Returns a new tensor with boolean elements representing if each element is <cite>finite</cite> or not.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.isin.html#torch.isin" title="torch.isin"><code><span>isin</span></code></a></p></td><td><p>Tests if each element of <code><span>elements</span></code> is in <code><span>test_elements</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.isinf.html#torch.isinf" title="torch.isinf"><code><span>isinf</span></code></a></p></td><td><p>Tests if each element of <code><span>input</span></code> is infinite (positive or negative infinity) or not.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.isposinf.html#torch.isposinf" title="torch.isposinf"><code><span>isposinf</span></code></a></p></td><td><p>Tests if each element of <code><span>input</span></code> is positive infinity or not.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.isneginf.html#torch.isneginf" title="torch.isneginf"><code><span>isneginf</span></code></a></p></td><td><p>Tests if each element of <code><span>input</span></code> is negative infinity or not.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.isnan.html#torch.isnan" title="torch.isnan"><code><span>isnan</span></code></a></p></td><td><p>Returns a new tensor with boolean elements representing if each element of <code><span>input</span></code> is NaN or not.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.isreal.html#torch.isreal" title="torch.isreal"><code><span>isreal</span></code></a></p></td><td><p>Returns a new tensor with boolean elements representing if each element of <code><span>input</span></code> is real-valued or not.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.kthvalue.html#torch.kthvalue" title="torch.kthvalue"><code><span>kthvalue</span></code></a></p></td><td><p>Returns a namedtuple <code><span>(values,</span> <span>indices)</span></code> where <code><span>values</span></code> is the <code><span>k</span></code> th smallest element of each row of the <code><span>input</span></code> tensor in the given dimension <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.le.html#torch.le" title="torch.le"><code><span>le</span></code></a></p></td><td><p>Computes <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>â‰¤</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} \leq \text{other}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>input</span></span><span></span><span>â‰¤</span><span></span></span><span><span></span><span><span>other</span></span></span></span></span></span> element-wise.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.less_equal.html#torch.less_equal" title="torch.less_equal"><code><span>less_equal</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.le.html#torch.le" title="torch.le"><code><span>torch.le()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.lt.html#torch.lt" title="torch.lt"><code><span>lt</span></code></a></p></td><td><p>Computes <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>&lt;</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} &lt; \text{other}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>input</span></span><span></span><span>&lt;</span><span></span></span><span><span></span><span><span>other</span></span></span></span></span></span> element-wise.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.less.html#torch.less" title="torch.less"><code><span>less</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.lt.html#torch.lt" title="torch.lt"><code><span>torch.lt()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.maximum.html#torch.maximum" title="torch.maximum"><code><span>maximum</span></code></a></p></td><td><p>Computes the element-wise maximum of <code><span>input</span></code> and <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.minimum.html#torch.minimum" title="torch.minimum"><code><span>minimum</span></code></a></p></td><td><p>Computes the element-wise minimum of <code><span>input</span></code> and <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.fmax.html#torch.fmax" title="torch.fmax"><code><span>fmax</span></code></a></p></td><td><p>Computes the element-wise maximum of <code><span>input</span></code> and <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.fmin.html#torch.fmin" title="torch.fmin"><code><span>fmin</span></code></a></p></td><td><p>Computes the element-wise minimum of <code><span>input</span></code> and <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.ne.html#torch.ne" title="torch.ne"><code><span>ne</span></code></a></p></td><td><p>Computes <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo mathvariant="normal">â‰ </mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} \neq \text{other}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>input</span></span><span></span><span><span><span><span><span><span></span><span><span><span>î€ </span></span></span><span></span></span></span></span></span><span>=</span></span><span></span></span><span><span></span><span><span>other</span></span></span></span></span></span> element-wise.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.not_equal.html#torch.not_equal" title="torch.not_equal"><code><span>not_equal</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.ne.html#torch.ne" title="torch.ne"><code><span>torch.ne()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sort.html#torch.sort" title="torch.sort"><code><span>sort</span></code></a></p></td><td><p>Sorts the elements of the <code><span>input</span></code> tensor along a given dimension in ascending order by value.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.topk.html#torch.topk" title="torch.topk"><code><span>topk</span></code></a></p></td><td><p>Returns the <code><span>k</span></code> largest elements of the given <code><span>input</span></code> tensor along a given dimension.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.msort.html#torch.msort" title="torch.msort"><code><span>msort</span></code></a></p></td><td><p>Sorts the elements of the <code><span>input</span></code> tensor along its first dimension in ascending order by value.</p></td></tr></tbody></table>

### Spectral Ops[](#spectral-ops)

### Other Operations[](#other-operations)

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.atleast_1d.html#torch.atleast_1d" title="torch.atleast_1d"><code><span>atleast_1d</span></code></a></p></td><td><p>Returns a 1-dimensional view of each input tensor with zero dimensions.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.atleast_2d.html#torch.atleast_2d" title="torch.atleast_2d"><code><span>atleast_2d</span></code></a></p></td><td><p>Returns a 2-dimensional view of each input tensor with zero dimensions.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.atleast_3d.html#torch.atleast_3d" title="torch.atleast_3d"><code><span>atleast_3d</span></code></a></p></td><td><p>Returns a 3-dimensional view of each input tensor with zero dimensions.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.bincount.html#torch.bincount" title="torch.bincount"><code><span>bincount</span></code></a></p></td><td><p>Count the frequency of each value in an array of non-negative ints.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.block_diag.html#torch.block_diag" title="torch.block_diag"><code><span>block_diag</span></code></a></p></td><td><p>Create a block diagonal matrix from provided tensors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.broadcast_tensors.html#torch.broadcast_tensors" title="torch.broadcast_tensors"><code><span>broadcast_tensors</span></code></a></p></td><td><p>Broadcasts the given tensors according to <a href="https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics"><span>Broadcasting semantics</span></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.broadcast_to.html#torch.broadcast_to" title="torch.broadcast_to"><code><span>broadcast_to</span></code></a></p></td><td><p>Broadcasts <code><span>input</span></code> to the shape <code><span>shape</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.broadcast_shapes.html#torch.broadcast_shapes" title="torch.broadcast_shapes"><code><span>broadcast_shapes</span></code></a></p></td><td><p>Similar to <a href="https://pytorch.org/docs/stable/generated/torch.broadcast_tensors.html#torch.broadcast_tensors" title="torch.broadcast_tensors"><code><span>broadcast_tensors()</span></code></a> but for shapes.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.bucketize.html#torch.bucketize" title="torch.bucketize"><code><span>bucketize</span></code></a></p></td><td><p>Returns the indices of the buckets to which each value in the <code><span>input</span></code> belongs, where the boundaries of the buckets are set by <code><span>boundaries</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cartesian_prod.html#torch.cartesian_prod" title="torch.cartesian_prod"><code><span>cartesian_prod</span></code></a></p></td><td><p>Do cartesian product of the given sequence of tensors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cdist.html#torch.cdist" title="torch.cdist"><code><span>cdist</span></code></a></p></td><td><p>Computes batched the p-norm distance between each pair of the two collections of row vectors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.clone.html#torch.clone" title="torch.clone"><code><span>clone</span></code></a></p></td><td><p>Returns a copy of <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.combinations.html#torch.combinations" title="torch.combinations"><code><span>combinations</span></code></a></p></td><td><p>Compute combinations of length <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>r</span></span></span></span></span> of the given tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.corrcoef.html#torch.corrcoef" title="torch.corrcoef"><code><span>corrcoef</span></code></a></p></td><td><p>Estimates the Pearson product-moment correlation coefficient matrix of the variables given by the <code><span>input</span></code> matrix, where rows are the variables and columns are the observations.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cov.html#torch.cov" title="torch.cov"><code><span>cov</span></code></a></p></td><td><p>Estimates the covariance matrix of the variables given by the <code><span>input</span></code> matrix, where rows are the variables and columns are the observations.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cross.html#torch.cross" title="torch.cross"><code><span>cross</span></code></a></p></td><td><p>Returns the cross product of vectors in dimension <code><span>dim</span></code> of <code><span>input</span></code> and <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cummax.html#torch.cummax" title="torch.cummax"><code><span>cummax</span></code></a></p></td><td><p>Returns a namedtuple <code><span>(values,</span> <span>indices)</span></code> where <code><span>values</span></code> is the cumulative maximum of elements of <code><span>input</span></code> in the dimension <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cummin.html#torch.cummin" title="torch.cummin"><code><span>cummin</span></code></a></p></td><td><p>Returns a namedtuple <code><span>(values,</span> <span>indices)</span></code> where <code><span>values</span></code> is the cumulative minimum of elements of <code><span>input</span></code> in the dimension <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cumprod.html#torch.cumprod" title="torch.cumprod"><code><span>cumprod</span></code></a></p></td><td><p>Returns the cumulative product of elements of <code><span>input</span></code> in the dimension <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cumsum.html#torch.cumsum" title="torch.cumsum"><code><span>cumsum</span></code></a></p></td><td><p>Returns the cumulative sum of elements of <code><span>input</span></code> in the dimension <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.diag.html#torch.diag" title="torch.diag"><code><span>diag</span></code></a></p></td><td><ul><li><p>If <code><span>input</span></code> is a vector (1-D tensor), then returns a 2-D square tensor</p></li></ul></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.diag_embed.html#torch.diag_embed" title="torch.diag_embed"><code><span>diag_embed</span></code></a></p></td><td><p>Creates a tensor whose diagonals of certain 2D planes (specified by <code><span>dim1</span></code> and <code><span>dim2</span></code>) are filled by <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.diagflat.html#torch.diagflat" title="torch.diagflat"><code><span>diagflat</span></code></a></p></td><td><ul><li><p>If <code><span>input</span></code> is a vector (1-D tensor), then returns a 2-D square tensor</p></li></ul></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.diagonal.html#torch.diagonal" title="torch.diagonal"><code><span>diagonal</span></code></a></p></td><td><p>Returns a partial view of <code><span>input</span></code> with the its diagonal elements with respect to <code><span>dim1</span></code> and <code><span>dim2</span></code> appended as a dimension at the end of the shape.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.diff.html#torch.diff" title="torch.diff"><code><span>diff</span></code></a></p></td><td><p>Computes the n-th forward difference along the given dimension.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum" title="torch.einsum"><code><span>einsum</span></code></a></p></td><td><p>Sums the product of the elements of the input <code><span>operands</span></code> along dimensions specified using a notation based on the Einstein summation convention.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten" title="torch.flatten"><code><span>flatten</span></code></a></p></td><td><p>Flattens <code><span>input</span></code> by reshaping it into a one-dimensional tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.flip.html#torch.flip" title="torch.flip"><code><span>flip</span></code></a></p></td><td><p>Reverse the order of an n-D tensor along given axis in dims.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.fliplr.html#torch.fliplr" title="torch.fliplr"><code><span>fliplr</span></code></a></p></td><td><p>Flip tensor in the left/right direction, returning a new tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.flipud.html#torch.flipud" title="torch.flipud"><code><span>flipud</span></code></a></p></td><td><p>Flip tensor in the up/down direction, returning a new tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.kron.html#torch.kron" title="torch.kron"><code><span>kron</span></code></a></p></td><td><p>Computes the Kronecker product, denoted by <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>âŠ—</mo></mrow><annotation encoding="application/x-tex">\otimes</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>âŠ—</span></span></span></span></span>, of <code><span>input</span></code> and <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.rot90.html#torch.rot90" title="torch.rot90"><code><span>rot90</span></code></a></p></td><td><p>Rotate an n-D tensor by 90 degrees in the plane specified by dims axis.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.gcd.html#torch.gcd" title="torch.gcd"><code><span>gcd</span></code></a></p></td><td><p>Computes the element-wise greatest common divisor (GCD) of <code><span>input</span></code> and <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.histc.html#torch.histc" title="torch.histc"><code><span>histc</span></code></a></p></td><td><p>Computes the histogram of a tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.histogram.html#torch.histogram" title="torch.histogram"><code><span>histogram</span></code></a></p></td><td><p>Computes a histogram of the values in a tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.histogramdd.html#torch.histogramdd" title="torch.histogramdd"><code><span>histogramdd</span></code></a></p></td><td><p>Computes a multi-dimensional histogram of the values in a tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.meshgrid.html#torch.meshgrid" title="torch.meshgrid"><code><span>meshgrid</span></code></a></p></td><td><p>Creates grids of coordinates specified by the 1D inputs in <cite>attr</cite>:tensors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.lcm.html#torch.lcm" title="torch.lcm"><code><span>lcm</span></code></a></p></td><td><p>Computes the element-wise least common multiple (LCM) of <code><span>input</span></code> and <code><span>other</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.logcumsumexp.html#torch.logcumsumexp" title="torch.logcumsumexp"><code><span>logcumsumexp</span></code></a></p></td><td><p>Returns the logarithm of the cumulative summation of the exponentiation of elements of <code><span>input</span></code> in the dimension <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.ravel.html#torch.ravel" title="torch.ravel"><code><span>ravel</span></code></a></p></td><td><p>Return a contiguous flattened tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.renorm.html#torch.renorm" title="torch.renorm"><code><span>renorm</span></code></a></p></td><td><p>Returns a tensor where each sub-tensor of <code><span>input</span></code> along dimension <code><span>dim</span></code> is normalized such that the <cite>p</cite>-norm of the sub-tensor is lower than the value <code><span>maxnorm</span></code></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.repeat_interleave.html#torch.repeat_interleave" title="torch.repeat_interleave"><code><span>repeat_interleave</span></code></a></p></td><td><p>Repeat elements of a tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.roll.html#torch.roll" title="torch.roll"><code><span>roll</span></code></a></p></td><td><p>Roll the tensor <code><span>input</span></code> along the given dimension(s).</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.searchsorted.html#torch.searchsorted" title="torch.searchsorted"><code><span>searchsorted</span></code></a></p></td><td><p>Find the indices from the <em>innermost</em> dimension of <code><span>sorted_sequence</span></code> such that, if the corresponding values in <code><span>values</span></code> were inserted before the indices, when sorted, the order of the corresponding <em>innermost</em> dimension within <code><span>sorted_sequence</span></code> would be preserved.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.tensordot.html#torch.tensordot" title="torch.tensordot"><code><span>tensordot</span></code></a></p></td><td><p>Returns a contraction of a and b over multiple dimensions.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.trace.html#torch.trace" title="torch.trace"><code><span>trace</span></code></a></p></td><td><p>Returns the sum of the elements of the diagonal of the input 2-D matrix.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.tril.html#torch.tril" title="torch.tril"><code><span>tril</span></code></a></p></td><td><p>Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices <code><span>input</span></code>, the other elements of the result tensor <code><span>out</span></code> are set to 0.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.tril_indices.html#torch.tril_indices" title="torch.tril_indices"><code><span>tril_indices</span></code></a></p></td><td><p>Returns the indices of the lower triangular part of a <code><span>row</span></code>-by- <code><span>col</span></code> matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.triu.html#torch.triu" title="torch.triu"><code><span>triu</span></code></a></p></td><td><p>Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices <code><span>input</span></code>, the other elements of the result tensor <code><span>out</span></code> are set to 0.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.triu_indices.html#torch.triu_indices" title="torch.triu_indices"><code><span>triu_indices</span></code></a></p></td><td><p>Returns the indices of the upper triangular part of a <code><span>row</span></code> by <code><span>col</span></code> matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.unflatten.html#torch.unflatten" title="torch.unflatten"><code><span>unflatten</span></code></a></p></td><td><p>Expands a dimension of the input tensor over multiple dimensions.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.vander.html#torch.vander" title="torch.vander"><code><span>vander</span></code></a></p></td><td><p>Generates a Vandermonde matrix.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.view_as_real.html#torch.view_as_real" title="torch.view_as_real"><code><span>view_as_real</span></code></a></p></td><td><p>Returns a view of <code><span>input</span></code> as a real tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.view_as_complex.html#torch.view_as_complex" title="torch.view_as_complex"><code><span>view_as_complex</span></code></a></p></td><td><p>Returns a view of <code><span>input</span></code> as a complex tensor.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.resolve_conj.html#torch.resolve_conj" title="torch.resolve_conj"><code><span>resolve_conj</span></code></a></p></td><td><p>Returns a new tensor with materialized conjugation if <code><span>input</span></code>'s conjugate bit is set to <cite>True</cite>, else returns <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.resolve_neg.html#torch.resolve_neg" title="torch.resolve_neg"><code><span>resolve_neg</span></code></a></p></td><td><p>Returns a new tensor with materialized negation if <code><span>input</span></code>'s negative bit is set to <cite>True</cite>, else returns <code><span>input</span></code>.</p></td></tr></tbody></table>

### BLAS and LAPACK Operations[](#blas-and-lapack-operations)

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm" title="torch.addbmm"><code><span>addbmm</span></code></a></p></td><td><p>Performs a batch matrix-matrix product of matrices stored in <code><span>batch1</span></code> and <code><span>batch2</span></code>, with a reduced add step (all matrix multiplications get accumulated along the first dimension).</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.addmm.html#torch.addmm" title="torch.addmm"><code><span>addmm</span></code></a></p></td><td><p>Performs a matrix multiplication of the matrices <code><span>mat1</span></code> and <code><span>mat2</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.addmv.html#torch.addmv" title="torch.addmv"><code><span>addmv</span></code></a></p></td><td><p>Performs a matrix-vector product of the matrix <code><span>mat</span></code> and the vector <code><span>vec</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.addr.html#torch.addr" title="torch.addr"><code><span>addr</span></code></a></p></td><td><p>Performs the outer-product of vectors <code><span>vec1</span></code> and <code><span>vec2</span></code> and adds it to the matrix <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.baddbmm.html#torch.baddbmm" title="torch.baddbmm"><code><span>baddbmm</span></code></a></p></td><td><p>Performs a batch matrix-matrix product of matrices in <code><span>batch1</span></code> and <code><span>batch2</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.bmm.html#torch.bmm" title="torch.bmm"><code><span>bmm</span></code></a></p></td><td><p>Performs a batch matrix-matrix product of matrices stored in <code><span>input</span></code> and <code><span>mat2</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.chain_matmul.html#torch.chain_matmul" title="torch.chain_matmul"><code><span>chain_matmul</span></code></a></p></td><td><p>Returns the matrix product of the <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>N</span></span></span></span></span> 2-D tensors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cholesky.html#torch.cholesky" title="torch.cholesky"><code><span>cholesky</span></code></a></p></td><td><p>Computes the Cholesky decomposition of a symmetric positive-definite matrix <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>A</span></span></span></span></span> or for batches of symmetric positive-definite matrices.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cholesky_inverse.html#torch.cholesky_inverse" title="torch.cholesky_inverse"><code><span>cholesky_inverse</span></code></a></p></td><td><p>Computes the inverse of a symmetric positive-definite matrix <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>A</span></span></span></span></span> using its Cholesky factor <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>u</span></span></span></span></span>: returns matrix <code><span>inv</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cholesky_solve.html#torch.cholesky_solve" title="torch.cholesky_solve"><code><span>cholesky_solve</span></code></a></p></td><td><p>Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>u</span></span></span></span></span>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot" title="torch.dot"><code><span>dot</span></code></a></p></td><td><p>Computes the dot product of two 1D tensors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.geqrf.html#torch.geqrf" title="torch.geqrf"><code><span>geqrf</span></code></a></p></td><td><p>This is a low-level function for calling LAPACK's geqrf directly.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.ger.html#torch.ger" title="torch.ger"><code><span>ger</span></code></a></p></td><td><p>Alias of <a href="https://pytorch.org/docs/stable/generated/torch.outer.html#torch.outer" title="torch.outer"><code><span>torch.outer()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.inner.html#torch.inner" title="torch.inner"><code><span>inner</span></code></a></p></td><td><p>Computes the dot product for 1D tensors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.inverse.html#torch.inverse" title="torch.inverse"><code><span>inverse</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.linalg.inv.html#torch.linalg.inv" title="torch.linalg.inv"><code><span>torch.linalg.inv()</span></code></a></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.det.html#torch.det" title="torch.det"><code><span>det</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.linalg.det.html#torch.linalg.det" title="torch.linalg.det"><code><span>torch.linalg.det()</span></code></a></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.logdet.html#torch.logdet" title="torch.logdet"><code><span>logdet</span></code></a></p></td><td><p>Calculates log determinant of a square matrix or batches of square matrices.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.slogdet.html#torch.slogdet" title="torch.slogdet"><code><span>slogdet</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.linalg.slogdet.html#torch.linalg.slogdet" title="torch.linalg.slogdet"><code><span>torch.linalg.slogdet()</span></code></a></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.lu.html#torch.lu" title="torch.lu"><code><span>lu</span></code></a></p></td><td><p>Computes the LU factorization of a matrix or batches of matrices <code><span>A</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve" title="torch.lu_solve"><code><span>lu_solve</span></code></a></p></td><td><p>Returns the LU solve of the linear system <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>x</mi><mo>=</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Ax = b</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>A</span><span>x</span><span></span><span>=</span><span></span></span><span><span></span><span>b</span></span></span></span></span> using the partially pivoted LU factorization of A from <a href="https://pytorch.org/docs/stable/generated/torch.linalg.lu_factor.html#torch.linalg.lu_factor" title="torch.linalg.lu_factor"><code><span>lu_factor()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.lu_unpack.html#torch.lu_unpack" title="torch.lu_unpack"><code><span>lu_unpack</span></code></a></p></td><td><p>Unpacks the LU decomposition returned by <a href="https://pytorch.org/docs/stable/generated/torch.linalg.lu_factor.html#torch.linalg.lu_factor" title="torch.linalg.lu_factor"><code><span>lu_factor()</span></code></a> into the <cite>P, L, U</cite> matrices.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.matmul.html#torch.matmul" title="torch.matmul"><code><span>matmul</span></code></a></p></td><td><p>Matrix product of two tensors.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.matrix_power.html#torch.matrix_power" title="torch.matrix_power"><code><span>matrix_power</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.linalg.matrix_power.html#torch.linalg.matrix_power" title="torch.linalg.matrix_power"><code><span>torch.linalg.matrix_power()</span></code></a></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.matrix_exp.html#torch.matrix_exp" title="torch.matrix_exp"><code><span>matrix_exp</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.linalg.matrix_exp.html#torch.linalg.matrix_exp" title="torch.linalg.matrix_exp"><code><span>torch.linalg.matrix_exp()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.mm.html#torch.mm" title="torch.mm"><code><span>mm</span></code></a></p></td><td><p>Performs a matrix multiplication of the matrices <code><span>input</span></code> and <code><span>mat2</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.mv.html#torch.mv" title="torch.mv"><code><span>mv</span></code></a></p></td><td><p>Performs a matrix-vector product of the matrix <code><span>input</span></code> and the vector <code><span>vec</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.orgqr.html#torch.orgqr" title="torch.orgqr"><code><span>orgqr</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.linalg.householder_product.html#torch.linalg.householder_product" title="torch.linalg.householder_product"><code><span>torch.linalg.householder_product()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.ormqr.html#torch.ormqr" title="torch.ormqr"><code><span>ormqr</span></code></a></p></td><td><p>Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.outer.html#torch.outer" title="torch.outer"><code><span>outer</span></code></a></p></td><td><p>Outer product of <code><span>input</span></code> and <code><span>vec2</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.pinverse.html#torch.pinverse" title="torch.pinverse"><code><span>pinverse</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv" title="torch.linalg.pinv"><code><span>torch.linalg.pinv()</span></code></a></p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.qr.html#torch.qr" title="torch.qr"><code><span>qr</span></code></a></p></td><td><p>Computes the QR decomposition of a matrix or a batch of matrices <code><span>input</span></code>, and returns a namedtuple (Q, R) of tensors such that <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>=</mo><mi>Q</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">\text{input} = Q R</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>input</span></span><span></span><span>=</span><span></span></span><span><span></span><span>QR</span></span></span></span></span> with <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>Q</span></span></span></span></span> being an orthogonal matrix or batch of orthogonal matrices and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>R</span></span></span></span></span> being an upper triangular matrix or batch of upper triangular matrices.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.svd.html#torch.svd" title="torch.svd"><code><span>svd</span></code></a></p></td><td><p>Computes the singular value decomposition of either a matrix or batch of matrices <code><span>input</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.svd_lowrank.html#torch.svd_lowrank" title="torch.svd_lowrank"><code><span>svd_lowrank</span></code></a></p></td><td><p>Return the singular value decomposition <code><span>(U,</span> <span>S,</span> <span>V)</span></code> of a matrix, batches of matrices, or a sparse matrix <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>A</span></span></span></span></span> such that <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>â‰ˆ</mo><mi>U</mi><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A \approx U diag(S) V^T</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>A</span><span></span><span>â‰ˆ</span><span></span></span><span><span></span><span>U</span><span>d</span><span>ia</span><span>g</span><span>(</span><span>S</span><span>)</span><span><span>V</span><span><span><span><span><span><span></span><span><span>T</span></span></span></span></span></span></span></span></span></span></span></span>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.pca_lowrank.html#torch.pca_lowrank" title="torch.pca_lowrank"><code><span>pca_lowrank</span></code></a></p></td><td><p>Performs linear Principal Component Analysis (PCA) on a low-rank matrix, batches of such matrices, or sparse matrix.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.lobpcg.html#torch.lobpcg" title="torch.lobpcg"><code><span>lobpcg</span></code></a></p></td><td><p>Find the k largest (or smallest) eigenvalues and the corresponding eigenvectors of a symmetric positive definite generalized eigenvalue problem using matrix-free LOBPCG methods.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.trapz.html#torch.trapz" title="torch.trapz"><code><span>trapz</span></code></a></p></td><td><p>Alias for <a href="https://pytorch.org/docs/stable/generated/torch.trapezoid.html#torch.trapezoid" title="torch.trapezoid"><code><span>torch.trapezoid()</span></code></a>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.trapezoid.html#torch.trapezoid" title="torch.trapezoid"><code><span>trapezoid</span></code></a></p></td><td><p>Computes the <a href="https://en.wikipedia.org/wiki/Trapezoidal_rule">trapezoidal rule</a> along <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.cumulative_trapezoid.html#torch.cumulative_trapezoid" title="torch.cumulative_trapezoid"><code><span>cumulative_trapezoid</span></code></a></p></td><td><p>Cumulatively computes the <a href="https://en.wikipedia.org/wiki/Trapezoidal_rule">trapezoidal rule</a> along <code><span>dim</span></code>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.triangular_solve.html#torch.triangular_solve" title="torch.triangular_solve"><code><span>triangular_solve</span></code></a></p></td><td><p>Solves a system of equations with a square upper or lower triangular invertible matrix <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>A</span></span></span></span></span> and multiple right-hand sides <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>b</span></span></span></span></span>.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.vdot.html#torch.vdot" title="torch.vdot"><code><span>vdot</span></code></a></p></td><td><p>Computes the dot product of two 1D vectors along a dimension.</p></td></tr></tbody></table>

### Foreach Operations[](#foreach-operations)

Warning

This API is in beta and subject to future changes. Forward-mode AD is not supported.

## Utilities[](#utilities)

## Symbolic Numbers[](#symbolic-numbers)

_class_ torch.SymInt(_node_)[[source]](https://pytorch.org/docs/stable/_modules/torch.html#SymInt)[](#torch.SymInt)

Like an int (including magic methods), but redirects all operations on the wrapped node. This is used in particular to symbolically record operations in the symbolic shape workflow.

_class_ torch.SymFloat(_node_)[[source]](https://pytorch.org/docs/stable/_modules/torch.html#SymFloat)[](#torch.SymFloat)

Like an float (including magic methods), but redirects all operations on the wrapped node. This is used in particular to symbolically record operations in the symbolic shape workflow.

_class_ torch.SymBool(_node_)[[source]](https://pytorch.org/docs/stable/_modules/torch.html#SymBool)[](#torch.SymBool)

Like an bool (including magic methods), but redirects all operations on the wrapped node. This is used in particular to symbolically record operations in the symbolic shape workflow.

Unlike regular bools, regular boolean operators will force extra guards instead of symbolically evaluate. Use the bitwise operators instead to handle this.

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sym_float.html#torch.sym_float" title="torch.sym_float"><code><span>sym_float</span></code></a></p></td><td><p>SymInt-aware utility for float casting.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sym_int.html#torch.sym_int" title="torch.sym_int"><code><span>sym_int</span></code></a></p></td><td><p>SymInt-aware utility for int casting.</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sym_max.html#torch.sym_max" title="torch.sym_max"><code><span>sym_max</span></code></a></p></td><td><p>SymInt-aware utility for max().</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sym_min.html#torch.sym_min" title="torch.sym_min"><code><span>sym_min</span></code></a></p></td><td><p>SymInt-aware utility for max().</p></td></tr><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.sym_not.html#torch.sym_not" title="torch.sym_not"><code><span>sym_not</span></code></a></p></td><td><p>SymInt-aware utility for logical negation.</p></td></tr></tbody></table>

## Optimizations[](#optimizations)

<table><tbody><tr><td><p><a href="https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile"><code><span>compile</span></code></a></p></td><td><p>Optimizes given model/function using TorchDynamo and specified backend.</p></td></tr></tbody></table>

## Operator Tags[](#operator-tags)

_class_ torch.Tag[](#torch.Tag)

Members:

nondeterministic_bitwise

pointwise

view_copy

nondeterministic_seeded

dynamic_output_shape

core

inplace_view

generated

data_dependent_output

_property_ name[](#torch.Tag.name)

`torch.autograd` provides classes and functions implementing automatic differentiation of arbitrary scalar valued functions. It requires minimal changes to the existing code - you only need to declare `Tensor` s for which gradients should be computed with the `requires_grad=True` keyword. As of now, we only support autograd for floating point `Tensor` types (half, float, double and bfloat16) and complex `Tensor` types (cfloat, cdouble).

## Engine Configuration[](#engine-configuration)